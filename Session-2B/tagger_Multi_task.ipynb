{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tagger_Multi-task.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLImtw4oo0WV",
        "colab_type": "text"
      },
      "source": [
        "# Multi-task Learning\n",
        "---\n",
        "\n",
        "<font size=\"4\"> \n",
        "  \n",
        "  Multi-task learning is an approach for jointly training multiple models. It can be simply implemented in neural networks by learning tasks in parallel while using a shared representation.\n",
        "  \n",
        "The simplest way is when we have different outputs for the same input and simultaneously train a model to predict the two or more outputs. \n",
        "  \n",
        "Parallel models can have both shared and independent layers.\n",
        "  \n",
        "  <figure>\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1LdwHoHlwm2wQj6SHUazYkNcavTCJp1_X\" width=\"400\" height=\"300\"/>\n",
        "<figcaption>Multi-task learning</figcaption></center>\n",
        "</figure>\n",
        "  \n",
        "In this excercise, we use the tags for chunking (which is provided in CONLL 2003 dataset in the third column) as our auxiliary outputs. The idea is that these two tasks can benefit from each other.\n",
        "  \n",
        "  \n",
        "The sections of the code that should be modified for multi-tasking are as follows:\n",
        "  \n",
        "\n",
        "\n",
        "* Modify `readfile()`, to read the chunking column as well\n",
        "* Create a dictionary that encode auxiliary tags\n",
        "* Return auxiliary tags from class `CoNLL2003NER(Dataset)`\n",
        "* Modify the model class. The architecture of the model will consist of one LSTM layer on top of embedding, then, two parallel LSTM layers, one to learn auxiliary tags and one to learn the main tags, and finally two Linear layers in similar fashion. The model returns two outputs accordingly.\n",
        "* In the training loop, two losses will be computed, one for main tags predictions and one for auxiliary tags prediction. Backpropagation would be performed based on the addition of the two losses.\n",
        " \n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF8OUxU6jSkE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "5a613873-1666-4c0d-b145-bcc2c37ba863"
      },
      "source": [
        "# The following two lines authorises access to Google Drive:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJnwvlt7jffE",
        "colab_type": "code",
        "outputId": "afa9a36e-0b73-4068-931b-a6201f8a4235",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import pdb\n",
        "import torch\n",
        "import gensim\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print(\"cuda device {}available\".format(\"\" if use_cuda else \"un\"))\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "\n",
        "# Parameters\n",
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM = 200\n",
        "BATCH_SIZE = 256 #300\n",
        "EPOCHS = 30\n",
        "LSTM_DROPOUT = 0.3\n",
        "USE_PRETRAINED = False\n",
        "\n",
        "# data dir\n",
        "data_folder = \"/content/drive/My Drive/DLinNLP/Data\"\n",
        "# embeddings folder \n",
        "embed_folder = \"/content/drive/My Drive/DLinNLP/embeddings\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda device available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GWyxC9mu32c",
        "colab_type": "text"
      },
      "source": [
        "## Data Format\n",
        "---\n",
        "<font size=\"4\"> One standard file format for representing IOB-annotated datasets is called CONLL. \n",
        "  \n",
        "A CONLL file contains one token per line and an empty line indicating the end of a sentence. Each token may be annotated by several tab-separated columns indicating information about the token (e.g. token raw form) or differrent tags assigned to it (e.g. syntactic and morphological labels).\n",
        "</font>\n",
        "\n",
        "<P>\n",
        "<table align=\"left\" style=\"width:100%\">\n",
        "  <tr>\n",
        "    <td>Welsh</td>\n",
        "    <td>NNP</td> \n",
        "    <td>B-NP</td>\n",
        "    <td><b>B-ORG</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>National</td>\n",
        "    <td>NNP</td> \n",
        "    <td>I-NP</td>\n",
        "    <td><b>I-ORG</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Farmers</td>\n",
        "    <td>NNP</td> \n",
        "    <td>I-NP</td>\n",
        "    <td><b>I-ORG</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>'</td>\n",
        "    <td>POS</td> \n",
        "    <td>B-NP</td>\n",
        "    <td><b>I-ORG</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Union</td>\n",
        "    <td>NNP</td> \n",
        "    <td>I-NP</td>\n",
        "    <td><b>I-ORG</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>(</td>\n",
        "    <td>(</td> \n",
        "    <td>O</td>\n",
        "    <td><b>O</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>NFU</td>\n",
        "    <td>NNP</td> \n",
        "    <td>B-NP</td>\n",
        "    <td><b>B-ORG</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>)</td>\n",
        "    <td>)</td> \n",
        "    <td>O</td>\n",
        "    <td><b>O</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>chairman</td>\n",
        "    <td>NN</td> \n",
        "    <td>B-NP</td>\n",
        "    <td><b>O</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>John</td>\n",
        "    <td>NNP</td> \n",
        "    <td>I-NP</td>\n",
        "    <td><b>B-PER</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Lloyd</td>\n",
        "    <td>NNP</td> \n",
        "    <td>I-NP</td>\n",
        "    <td><b>I-PER</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>said</td>\n",
        "    <td>VBD</td> \n",
        "    <td>B-VP</td>\n",
        "    <td><b>O</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>on</td>\n",
        "    <td>IN</td> \n",
        "    <td>B-PP</td>\n",
        "    <td><b>O</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>BBC</td>\n",
        "    <td>NNP</td> \n",
        "    <td>B-NP</td>\n",
        "    <td><b>B-ORG</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>radio</td>\n",
        "    <td>NN</td> \n",
        "    <td>I-NP</td>\n",
        "    <td><b>I-ORG</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>.</td>\n",
        "    <td>.</td> \n",
        "    <td>O</td>\n",
        "    <td><b>O</b></td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td><br></tr>\n",
        "    <td><font size=\"4\"> Here, we read the CONLL 2003 dataset! <font></td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "<br>\n",
        "</P> \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpafGCXojfcB",
        "colab_type": "code",
        "outputId": "c5e24e21-a2ed-4465-c353-db23dd690efd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#\n",
        "# This fuction has been modified to read the chunking column as well.\n",
        "\n",
        "def readfile(filename):\n",
        "    f = open(filename)\n",
        "    sentences = []\n",
        "    sentence = []\n",
        "    for line in f:\n",
        "        if len(line) == 0 or line.startswith('-DOCSTART') or line[0] == \"\\n\":\n",
        "            if len(sentence) > 0:\n",
        "                sentences.append(sentence)\n",
        "                sentence = []\n",
        "            continue\n",
        "        splits = line.split(' ')\n",
        "        sentence.append([splits[0].strip(), splits[-2].strip(), splits[-1].strip()])\n",
        "\n",
        "    if len(sentence) > 0:\n",
        "        sentences.append(sentence)\n",
        "        sentence = []\n",
        "    sentences = [tuple(zip(*l)) for l in sentences]\n",
        "    return sentences\n",
        "\n",
        "train_data = np.array(readfile(data_folder+'/train.txt'))\n",
        "dev_data = np.array(readfile(data_folder+'/dev.txt'))\n",
        "test_data = np.array(readfile(data_folder+'/test.txt'))\n",
        "\n",
        "#train_data = train_data[0:6000,:]\n",
        "print(train_data.shape)\n",
        "print(train_data[0])\n",
        "print(dev_data.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(14041, 3)\n",
            "[('EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.')\n",
            " ('B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'O')\n",
            " ('B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O')]\n",
            "(3250, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXW2CYLTA8zf",
        "colab_type": "text"
      },
      "source": [
        "## Pre-processing \n",
        "---\n",
        "\n",
        "<font size=\"4\">It is common to sort data instances based on their lengths. This way, the lengths of sequences in each batch would be more homogeneous. \n",
        "<font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL_zgRz6jfYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This reordering is useful for padding\n",
        "def tensor_reorder(data):\n",
        "    \"\"\"reorders tensors from longest to shortest\"\"\"\n",
        "    lengths = [len(i[0]) for i in data]\n",
        "    max_len = max(lengths)\n",
        "    lengths = torch.LongTensor(lengths)\n",
        "    lengths, perm_idx = lengths.sort(0, descending=True)\n",
        "    data = data[perm_idx]\n",
        "    return data\n",
        "\n",
        "train_data = tensor_reorder(train_data)\n",
        "dev_data = tensor_reorder(dev_data)\n",
        "\n",
        "test_data = tensor_reorder(test_data)\n",
        "\n",
        "MAX_LEN = max(len(train_data[0][0]), len(dev_data[0][0])) # we set the maximum length from the max seq in train "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wMKVnTrjfWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here, we create a dictionary that maps all words to indices (for encoding)\n",
        "\n",
        "all_words = list(set([w for sent in np.concatenate((train_data,dev_data), axis=0) for w in sent[0]]))\n",
        "\n",
        "word_to_ix = {t:i+2 for i, t in enumerate(all_words)}\n",
        "word_to_ix['<PAD>'] = 0\n",
        "word_to_ix['<UNK>'] = 1\n",
        "\n",
        "\n",
        "all_tags_aux = list(set([tag for sent in np.concatenate((train_data,dev_data), axis=0) for tag in sent[1]]))\n",
        "tag_to_ix_aux = {t:i+1 for i, t in enumerate(all_tags_aux)}\n",
        "tag_to_ix_aux['<PAD>'] = 0\n",
        "ix_to_tag_aux = {v: k for k, v in tag_to_ix_aux.items()}\n",
        "\n",
        "# The tagset is simplified (NE categories not included) \n",
        "tag_to_ix = {'<PAD>':0, 'B-MISC':1, 'B-LOC':1, 'B-ORG':1, 'B-PER':1,\n",
        "             'I-MISC':2, 'I-PER':2, 'I-ORG':2, 'I-LOC':2, 'O':3}\n",
        "ix_to_tag = {0:'<PAD>', 1:'B', 2:'I', 3:'O'}\n",
        "\n",
        "## If we wanted to consider tags in their entirety:\n",
        "# all_tags = list(set([tag for sent_tag in train_data for tag in sent_tag[1]]))\n",
        "# tag_to_ix = {t:i+1 for i, t in enumerate(all_tags)}\n",
        "# tag_to_ix['<PAD>'] = 0\n",
        "# ix_to_tag = {v: k for k, v in tag_to_ix.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ5P-gPUjhRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This class creates a generator of data batches in order to faster the access to data.\n",
        "class CoNLL2003NER(Dataset):\n",
        "\n",
        "    def __init__(self, X, max_len, word_to_ix, tag_to_ix_aux, tag_to_ix):\n",
        "        self.X = X\n",
        "        self.max_len = max_len\n",
        "        self.word_to_ix = word_to_ix\n",
        "        self.tag_to_ix_aux = tag_to_ix_aux\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        \n",
        "    def transform(self, seq, to_ix):\n",
        "        idxs = [to_ix[w] if w in to_ix else 1 for w in seq]\n",
        "        if len(idxs) > self.max_len:\n",
        "            # Truncating\n",
        "            idxs = idxs[:self.max_len]    \n",
        "        else:\n",
        "            # Padding\n",
        "            idxs += [0]*(self.max_len-len(seq))\n",
        "        \n",
        "        return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.transform(self.X[idx][0],word_to_ix), self.transform(self.X[idx][1], tag_to_ix_aux), self.transform(self.X[idx][2], tag_to_ix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6kv5mDemXfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {'batch_size': BATCH_SIZE,\n",
        "          'shuffle': False,\n",
        "          'num_workers': 6,\n",
        "          'drop_last':True}\n",
        "\n",
        "\n",
        "train_data = CoNLL2003NER(train_data, MAX_LEN, word_to_ix, tag_to_ix_aux, tag_to_ix)\n",
        "train_data_generator = DataLoader(train_data, **params)\n",
        "\n",
        "test_data = CoNLL2003NER(test_data, MAX_LEN, word_to_ix, tag_to_ix_aux, tag_to_ix)\n",
        "test_data_generator = DataLoader(test_data, **params)\n",
        "\n",
        "dev_data = CoNLL2003NER(dev_data, MAX_LEN, word_to_ix, tag_to_ix_aux, tag_to_ix)\n",
        "dev_data_generator = DataLoader(dev_data, **params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_P8G0y54rpr8",
        "colab_type": "text"
      },
      "source": [
        "<font size=\"4\"> As you remember, in PyTorch, we build a class that inherits from Pytorch's nn.Module and includes two critical functions: <i>\\_\\_init\\_\\_</i> and <i>forward</i>.\n",
        "  </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Gm5mWQlmXbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# An LSTM_based Tgger for Multi-task learning\n",
        "class LSTMTagger(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, aux_tagset_size, tagset_size, max_len):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        \n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim) \n",
        "        \n",
        "        ### TO DO ####   \n",
        "        # load weights from pre-trained vectors or with random initialization \n",
        "        \n",
        "        ### TO DO ####\n",
        "        ### Add other layers to the Model ###\n",
        "        self.lstm1 = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, dropout=LSTM_DROPOUT, bidirectional=True, num_layers=1)\n",
        "        self.lstm2a = nn.LSTM(2 * hidden_dim, hidden_dim, batch_first=True, dropout=LSTM_DROPOUT, bidirectional=True, num_layers=1)\n",
        "        self.lstm2b = nn.LSTM(2 * hidden_dim, hidden_dim, batch_first=True, dropout=LSTM_DROPOUT, bidirectional=True, num_layers=1)\n",
        "\n",
        "        \n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2aux_tag = nn.Linear(2*hidden_dim, aux_tagset_size)\n",
        "        self.hidden2tag = nn.Linear(2*hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, sentence): \n",
        "        embeds = self.word_embeddings(sentence)     # SHAPE: [BATCH_SIZE,MAX_LEN,WORD_EMBEDDING_DIM]\n",
        "        \n",
        "        lstm_shared, _ = self.lstm1(embeds)\n",
        "        \n",
        "        lstm_out_aux, _ = self.lstm2a(lstm_shared)\n",
        "        aux_tag_space = self.hidden2aux_tag(lstm_out_aux)\n",
        "        aux_tag_scores = F.log_softmax(aux_tag_space, dim=-1) \n",
        "        \n",
        "        lstm_out, _ = self.lstm2b(lstm_shared)\n",
        "        tag_space = self.hidden2tag(lstm_out)\n",
        "        tag_scores = F.log_softmax(tag_space, dim=-1) \n",
        "        \n",
        "        return aux_tag_scores, tag_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBoxn3i6mXX_",
        "colab_type": "code",
        "outputId": "ea1ab81b-8731-4319-cd45-99f0e8639fa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(ix_to_tag_aux), len(ix_to_tag), MAX_LEN).to(device)\n",
        "\n",
        "# The negative log likelihood loss. \n",
        "# It is useful to train a classification problem with C classes.\n",
        "loss_function = nn.NLLLoss(ignore_index=0)  \n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001) \n",
        "\n",
        "print(model)\n",
        "print(model.parameters)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTMTagger(\n",
            "  (word_embeddings): Embedding(26885, 300)\n",
            "  (lstm1): LSTM(300, 200, batch_first=True, dropout=0.3, bidirectional=True)\n",
            "  (lstm2a): LSTM(400, 200, batch_first=True, dropout=0.3, bidirectional=True)\n",
            "  (lstm2b): LSTM(400, 200, batch_first=True, dropout=0.3, bidirectional=True)\n",
            "  (hidden2aux_tag): Linear(in_features=400, out_features=22, bias=True)\n",
            "  (hidden2tag): Linear(in_features=400, out_features=4, bias=True)\n",
            ")\n",
            "<bound method Module.parameters of LSTMTagger(\n",
            "  (word_embeddings): Embedding(26885, 300)\n",
            "  (lstm1): LSTM(300, 200, batch_first=True, dropout=0.3, bidirectional=True)\n",
            "  (lstm2a): LSTM(400, 200, batch_first=True, dropout=0.3, bidirectional=True)\n",
            "  (lstm2b): LSTM(400, 200, batch_first=True, dropout=0.3, bidirectional=True)\n",
            "  (hidden2aux_tag): Linear(in_features=400, out_features=22, bias=True)\n",
            "  (hidden2tag): Linear(in_features=400, out_features=4, bias=True)\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPfxkFwB3Ngk",
        "colab_type": "code",
        "outputId": "101d9956-809c-49f0-d938-f9feaf9d96b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Check the number of parameters\n",
        "pp=0\n",
        "for p in list(model.parameters()):\n",
        "        nn=1\n",
        "        for s in list(p.size()):\n",
        "            nn = nn*s\n",
        "        pp += nn\n",
        "print(pp)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10805526\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PetKGeMUmXUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oG8FVrcmXMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Early stopping procedure\n",
        "def early_stop(losses, patience):\n",
        "    \"\"\"stop execution if there is consecutive decline/stagnation in the loss values.\n",
        "       patience determines how quickly we take action. \n",
        "    \"\"\"\n",
        "    stop = False\n",
        "    patience += 1\n",
        "    if len(losses)>patience and min(losses[-patience:])==losses[-patience]:\n",
        "        stop = True\n",
        "    return stop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnB2nxhJmXC_",
        "colab_type": "code",
        "outputId": "6cf355f4-a880-4dbc-93a5-2081ac1b7f58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "def trainer(model, epochs):\n",
        "    \"\"\"train the model for the specified # of epochs\"\"\"\n",
        "    \n",
        "    \n",
        "    avg_train_losses = []\n",
        "    avg_valid_losses = [] \n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "                ################\n",
        "                ## train mode ##\n",
        "                ################\n",
        "        model.train() # set the model to training mode  \n",
        "        print('Epoch:', epoch+1)\n",
        "        t0 = time.time()\n",
        "        n_correct, n_total = 0, 0\n",
        "         \n",
        "        batch_losses = []\n",
        "        valid_losses = []\n",
        "        for sentences, aux_tags, tags in train_data_generator:\n",
        "            sentences, tags = sentences.to(device), tags.to(device)\n",
        "            aux_tags = aux_tags.to(device)\n",
        "            \n",
        "            # clear gradients \n",
        "            model.zero_grad()\n",
        "\n",
        "            # Run forward pass\n",
        "            predictions_aux, predictions = model(sentences)\n",
        "            \n",
        "            # compute the loss, gradients, and update the parameters\n",
        "            predictions = predictions.permute(0,2,1)       # loss presumes labels to come 2nd (hence the permute)\n",
        "            predictions_aux = predictions_aux.permute(0,2,1)       # loss presumes labels to come 2nd (hence the permute)\n",
        "            \n",
        "            batch_loss_prim = loss_function(predictions, tags)  # This computes average loss over all instances of the batch \n",
        "            batch_loss_aux = loss_function(predictions_aux, aux_tags)\n",
        "            \n",
        "            batch_loss = batch_loss_prim + batch_loss_aux\n",
        "            #print(batch_loss)\n",
        "            \n",
        "            batch_losses.append(batch_loss_prim.item())\n",
        "            \n",
        "            # compute number of correct predictions per epoch   \n",
        "            outputs = torch.argmax(predictions, dim=1)        \n",
        "            \n",
        "            n_correct += torch.sum(outputs==tags, dtype=torch.float)\n",
        "            n_total += float(tags.size(0) * tags.size(1))  # denominator: batch_size * max_len (e.g. 100 * 52)\n",
        "            \n",
        "            batch_loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        epoch_acc = n_correct/n_total\n",
        "        epoch_loss = np.average(batch_losses)\n",
        "        avg_train_losses.append(epoch_loss) # for keeping track of avg train losses\n",
        "  \n",
        "                ################\n",
        "                ## eval mode ###\n",
        "                ################\n",
        "        model.eval() # set the model to eval mode\n",
        "        for valid_sentences, valid_tags_aux, valid_tags in dev_data_generator:\n",
        "            valid_sentences, valid_tags_aux, valid_tags = valid_sentences.to(device), valid_tags_aux.to(device), valid_tags.to(device)\n",
        "            \n",
        "            # Run forward pass. Note since we are in eval mode, we don't need to set grad to zero  \n",
        "            _, valid_predictions = model(valid_sentences)\n",
        "            valid_predictions = valid_predictions.permute(0,2,1)\n",
        "            # calculate the average loss \n",
        "            valid_batch_loss = loss_function(valid_predictions, valid_tags)\n",
        "            valid_losses.append(valid_batch_loss.item())\n",
        "            \n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_valid_losses.append(valid_loss)\n",
        "        \n",
        "        t = time.time()\n",
        "        print('epoch loss: {}\\tepoch acc: {}\\tvalid loss:{}\\ttime:{}'.format(epoch_loss, epoch_acc.item(), valid_loss, t-t0))\n",
        "        \n",
        "        ### TO DO ###    \n",
        "        # Early Stopping\n",
        "        # end training if validation losses stagnate/increase \n",
        "        if early_stop(avg_valid_losses, patience=5):\n",
        "            print(\"Early stopping...\")\n",
        "            break\n",
        "        \n",
        "        ### TO DO ###    \n",
        "        # Saving the best Model\n",
        "        \n",
        "    return model, avg_train_losses, avg_valid_losses \n",
        "            \n",
        "model, avg_train_losses, avg_valid_losses = trainer(model, EPOCHS)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "epoch loss: 0.6525895766637944\tepoch acc: 0.11225699633359909\tvalid loss:0.6201728185017904\ttime:21.972609281539917\n",
            "Epoch: 2\n",
            "epoch loss: 0.3647920795612865\tepoch acc: 0.11194908618927002\tvalid loss:0.446022666990757\ttime:21.90899658203125\n",
            "Epoch: 3\n",
            "epoch loss: 0.21821879078116682\tepoch acc: 0.11710620671510696\tvalid loss:0.23622154320279756\ttime:21.90216898918152\n",
            "Epoch: 4\n",
            "epoch loss: 0.1262142445754122\tepoch acc: 0.122630774974823\tvalid loss:0.23391728848218918\ttime:22.16938328742981\n",
            "Epoch: 5\n",
            "epoch loss: 0.08507939634189286\tepoch acc: 0.12466072291135788\tvalid loss:0.22451132784287134\ttime:22.10663676261902\n",
            "Epoch: 6\n",
            "epoch loss: 0.059642010946171706\tepoch acc: 0.12620478868484497\tvalid loss:0.16199050409098467\ttime:22.1860511302948\n",
            "Epoch: 7\n",
            "epoch loss: 0.031815425397966196\tepoch acc: 0.12829618155956268\tvalid loss:0.16706143071254095\ttime:22.04697847366333\n",
            "Epoch: 8\n",
            "epoch loss: 0.019104926549415622\tepoch acc: 0.1291303038597107\tvalid loss:0.16481681416432062\ttime:22.168050289154053\n",
            "Epoch: 9\n",
            "epoch loss: 0.011796342172332245\tepoch acc: 0.1295822560787201\tvalid loss:0.22004642399648824\ttime:22.05555272102356\n",
            "Epoch: 10\n",
            "epoch loss: 0.009403312037681678\tepoch acc: 0.12959890067577362\tvalid loss:0.21606479088465372\ttime:22.11830735206604\n",
            "Epoch: 11\n",
            "epoch loss: 0.007338857017371252\tepoch acc: 0.12979096174240112\tvalid loss:0.1995669628183047\ttime:22.133626222610474\n",
            "Early stopping...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa4vzoEReMeB",
        "colab_type": "code",
        "outputId": "b07f9c5b-5427-46f5-8e13-f098d498eec8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        }
      },
      "source": [
        "# Visualizing the loss as the network trained\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "\n",
        "plt.plot(range(1,len(avg_train_losses)+1),avg_train_losses, label='Training Loss')\n",
        "plt.plot(range(1,len(avg_valid_losses)+1),avg_valid_losses,label='Validation Loss')\n",
        "\n",
        "#plt.ylim(1.8, 2.2)\n",
        "\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "\n",
        "# find position of lowest validation loss\n",
        "minposs = avg_valid_losses.index(min(avg_valid_losses))+1 \n",
        "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping')\n",
        "\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAHgCAYAAADt8bqrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9XRK1GJSjBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define evaluation metrics (acc, precision, recall, and f1-score)\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "class Evaluate():\n",
        "    def __init__(self, out, labels):\n",
        "        self.out = out.numpy().flatten()\n",
        "        self.labels = labels.numpy().flatten()\n",
        "    def accuracy(self):\n",
        "        nb_correct = sum(y_t==y_p for y_t, y_p in zip(self.labels, self.out))\n",
        "        nb_true = len(self.labels)\n",
        "        score = nb_correct / nb_true\n",
        "        return score\n",
        "    def precision_recall_fscore(self, tag_list, average='macro'):\n",
        "        return precision_recall_fscore_support(self.labels, self.out, \n",
        "                                                  average=average,labels=tag_list)[:-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tWDZVOimW6L",
        "colab_type": "code",
        "outputId": "2f0eff88-4fc6-481b-91aa-e7ff460fa360",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# evaluate the model on test set \n",
        "\n",
        "all_preds = torch.LongTensor().to(device)\n",
        "all_labels = torch.LongTensor().to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for sent, aux_target, target in test_data_generator:\n",
        "        sent, target = sent.to(device), target.to(device)\n",
        "        _, tag_scores = model(sent)\n",
        "        \n",
        "        predict = tag_scores.data.max(2, keepdim=True)[1]        \n",
        "        all_preds = torch.cat([all_preds, predict])\n",
        "        all_labels = torch.cat([all_labels,target])\n",
        "    \n",
        "    all_preds, all_labels = all_preds.cpu(), all_labels.cpu()\n",
        "    all_preds = all_preds.squeeze(dim=-1)\n",
        "    print()\n",
        "    evaluator = Evaluate(all_preds, all_labels)\n",
        "    print('Overall Results on the Test set:')\n",
        "    print('Accuracy\\t{}'.format(evaluator.accuracy()))\n",
        "    pr, rc, fm = evaluator.precision_recall_fscore(tag_list=[1,2,3]) # we ignore pad  \n",
        "    print('Precision\\t{}\\nRecall\\t\\t{}\\nF1-score\\t{}'.format(pr,rc,fm))\n",
        "    \n",
        "    print('\\n==================\\n')\n",
        "    \n",
        "    print('# Results ignoring O:\\n')\n",
        "    tag_list = [1,2] # we ignore both pad and O\n",
        "    pr, rc, fm = evaluator.precision_recall_fscore(tag_list)\n",
        "    print('Precision\\t{}\\nRecall\\t\\t{}\\nF1-score\\t{}'.format(pr,rc,fm))         "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Overall Results on the Test set:\n",
            "Accuracy\t0.11595632658270932\n",
            "Precision\t0.6332383832053213\n",
            "Recall\t\t0.7997608951755261\n",
            "F1-score\t0.5878407598759661\n",
            "\n",
            "==================\n",
            "\n",
            "# Results ignoring O:\n",
            "\n",
            "Precision\t0.8988167621813135\n",
            "Recall\t\t0.7054185848834451\n",
            "F1-score\t0.7892351302096483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6EP7vrK45xK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-k0ILVz45vD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp4BAe_k45pB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT7e_EZq44T1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u00iumtg44Id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}