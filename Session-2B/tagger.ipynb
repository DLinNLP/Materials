{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tagger.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLImtw4oo0WV",
        "colab_type": "text"
      },
      "source": [
        "# Sequence Tagging\n",
        "---\n",
        "\n",
        "<font size=\"4\"> Tagging is the task of labelling each word in a sentence. Examples are: Part-of-Speech (POS) tagging, Named Entity Recognition (NER) and Semantic Role Labelling (SRL).\n",
        "  \n",
        "Sequence tagging can be treated as a set of independent classification tasks targeting each individual component of a sequence. However, ideally a model considers context when assigning labels to each component. \n",
        "\n",
        "Formally, the challenge in tagging is to learn a function that maps a sequence of observations x = (<i>x<sub>1</sub>,x<sub>2</sub>,....x<sub>n</sub></i>) to a label sequence y = (<i>y<sub>1</sub>,y<sub>2</sub>,...,y<sub>n</sub></i>), where <i>y<sub>i</sub></i> belongs to a set of tags, which in the case of POS tagging would be Noun, Verb, Adjective, or similar.\n",
        "\n",
        "In some tasks, a chunk in a sequence receives a label, such as <i>Cherno More</i> or <i>Black Sea</i> in \"Cherno More is the Bulgarian name of the Black Sea\". \n",
        "\n",
        "In such cases, it is a standard practice to annotate the data using the <b>IOB scheme</b>.\n",
        "\n",
        "Each element gets a label indicating whether it occurs in the beginning of chunk X (B-X), inside chunk X (I-x) or outside of any chunk (O).\n",
        "\n",
        "Common issues in tagging include:\n",
        "<ul>\n",
        "<li> Large set of features\n",
        "<li> Smaller amount of data\n",
        "<li> Expensive memory and time costs\n",
        "</ul>\n",
        "\n",
        "<br>\n",
        "  \n",
        "---\n",
        "In this notebook, we implement an <b>LSTM-based NER system</b> for CONLL2003 dataset.\n",
        "  \n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm5ZYINAn6lM",
        "colab_type": "text"
      },
      "source": [
        "## Let's start!\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF8OUxU6jSkE",
        "colab_type": "code",
        "outputId": "4d8cd71d-599f-4c6d-fae3-12653a175ac1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# The following two lines authorises access to Google Drive:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJnwvlt7jffE",
        "colab_type": "code",
        "outputId": "5b206f4e-c53b-4383-c9b5-f0fdfcdecc86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import pdb\n",
        "import torch\n",
        "import gensim\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print(\"cuda device {}available\".format(\"\" if use_cuda else \"un\"))\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "\n",
        "# Parameters\n",
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM = 200\n",
        "BATCH_SIZE = 32 #300\n",
        "EPOCHS = 10\n",
        "LSTM_DROPOUT = 0.3\n",
        "USE_PRETRAINED = False\n",
        "\n",
        "# data dir\n",
        "data_folder = \"/content/drive/My Drive/Session-2B/Data\"\n",
        "# embeddings folder \n",
        "embed_folder = \"/content/drive/My Drive/Sessin-2B/Embeddings\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda device available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GWyxC9mu32c",
        "colab_type": "text"
      },
      "source": [
        "## Data Format\n",
        "---\n",
        "<font size=\"4\"> One standard file format for representing tagged pieces of text is CONLL. \n",
        "  \n",
        "A CONLL file contains one token per line and an empty line indicating the end of a sentence. Each token may be annotated by several tab-separated columns indicating information about the token (e.g. token raw form) or differrent tags assigned to it (e.g. syntactic and morphological labels).\n",
        "</font>\n",
        "\n",
        "<P>\n",
        "<table align=\"left\" style=\"width:100%\">\n",
        "  <tr>\n",
        "    <td>Welsh</td>\n",
        "    <td>NNP</td> \n",
        "    <td>B-NP</td>\n",
        "    <td><b>B-ORG</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>National</td>\n",
        "    <td>NNP</td> \n",
        "    <td>I-NP</td>\n",
        "    <td><b>I-ORG</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Farmers</td>\n",
        "    <td>NNP</td> \n",
        "    <td>I-NP</td>\n",
        "    <td><b>I-ORG</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>'</td>\n",
        "    <td>POS</td> \n",
        "    <td>B-NP</td>\n",
        "    <td><b>I-ORG</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Union</td>\n",
        "    <td>NNP</td> \n",
        "    <td>I-NP</td>\n",
        "    <td><b>I-ORG</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>(</td>\n",
        "    <td>(</td> \n",
        "    <td>O</td>\n",
        "    <td><b>O</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>NFU</td>\n",
        "    <td>NNP</td> \n",
        "    <td>B-NP</td>\n",
        "    <td><b>B-ORG</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>)</td>\n",
        "    <td>)</td> \n",
        "    <td>O</td>\n",
        "    <td><b>O</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>chairman</td>\n",
        "    <td>NN</td> \n",
        "    <td>B-NP</td>\n",
        "    <td><b>O</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>John</td>\n",
        "    <td>NNP</td> \n",
        "    <td>I-NP</td>\n",
        "    <td><b>B-PER</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Lloyd</td>\n",
        "    <td>NNP</td> \n",
        "    <td>I-NP</td>\n",
        "    <td><b>I-PER</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>said</td>\n",
        "    <td>VBD</td> \n",
        "    <td>B-VP</td>\n",
        "    <td><b>O</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>on</td>\n",
        "    <td>IN</td> \n",
        "    <td>B-PP</td>\n",
        "    <td><b>O</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>BBC</td>\n",
        "    <td>NNP</td> \n",
        "    <td>B-NP</td>\n",
        "    <td><b>B-ORG</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>radio</td>\n",
        "    <td>NN</td> \n",
        "    <td>I-NP</td>\n",
        "    <td><b>I-ORG</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>.</td>\n",
        "    <td>.</td> \n",
        "    <td>O</td>\n",
        "    <td><b>O</b></td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td><br></tr>\n",
        "    <td><font size=\"4\"> Here, we read the CONLL 2003 dataset! <font></td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "<br>\n",
        "</P> \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpafGCXojfcB",
        "colab_type": "code",
        "outputId": "8ce56a5b-b504-40a4-93f3-94f30209a2ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "def readfile(filename):\n",
        "    f = open(filename)\n",
        "    sentences = []\n",
        "    sentence = []\n",
        "    for line in f:\n",
        "        if len(line) == 0 or line.startswith('-DOCSTART') or line[0] == \"\\n\":\n",
        "            if len(sentence) > 0:\n",
        "                sentences.append(sentence)\n",
        "                sentence = []\n",
        "            continue\n",
        "        splits = line.split(' ')\n",
        "        sentence.append([splits[0].strip(), splits[-1].strip()])\n",
        "\n",
        "    if len(sentence) > 0:\n",
        "        sentences.append(sentence)\n",
        "        sentence = []\n",
        "    sentences = [tuple(zip(*l)) for l in sentences]\n",
        "    return sentences\n",
        "\n",
        "train_data = np.array(readfile(data_folder+'/train.txt'))\n",
        "dev_data = np.array(readfile(data_folder+'/dev.txt'))\n",
        "test_data = np.array(readfile(data_folder+'/test.txt'))\n",
        "\n",
        "print(\"train_data shape: \",train_data.shape)\n",
        "print(\"One instance of data: \",train_data[0])\n",
        "print(\"dev_data shape: \",dev_data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_data shape:  (14041, 2)\n",
            "One instance of data:  [('EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.')\n",
            " ('B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O')]\n",
            "dev_data shape:  (3250, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXW2CYLTA8zf",
        "colab_type": "text"
      },
      "source": [
        "## Pre-processing \n",
        "---\n",
        "\n",
        "<font size=\"4\">It is common to sort data instances based on their lengths. This way, the lengths of sequences in each batch would be more or less homogeneous. \n",
        "<font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL_zgRz6jfYi",
        "colab_type": "code",
        "outputId": "d471ccc4-352d-4c2f-af47-1ab8474c5685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# This reordering is useful for padding\n",
        "def tensor_reorder(data):\n",
        "    \"\"\"reorders tensors from longest to shortest\"\"\"\n",
        "    lengths = [len(i[0]) for i in data]\n",
        "    max_len = max(lengths)\n",
        "    lengths = torch.LongTensor(lengths)\n",
        "    lengths, perm_idx = lengths.sort(0, descending=True)\n",
        "    data = data[perm_idx]\n",
        "    return data\n",
        "\n",
        "train_data = tensor_reorder(train_data)\n",
        "dev_data = tensor_reorder(dev_data)\n",
        "test_data = tensor_reorder(test_data)\n",
        "\n",
        "MAX_LEN = max(len(train_data[0][0]), len(dev_data[0][0])) # we set the maximum length from the max seq in train and dev \n",
        "print(\"Data Reordered!\")\n",
        "print(\"maximum len of sentences:\", MAX_LEN)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Reordered!\n",
            "maximum len of sentences: 113\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wMKVnTrjfWN",
        "colab_type": "code",
        "outputId": "9710f911-c228-4038-b8aa-533f36302e31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Here, we create a dictionary that maps all words to indices (for encoding)\n",
        "\n",
        "all_words = list(set([w for sent in np.concatenate((train_data,dev_data), axis=0) for w in sent[0]]))\n",
        "\n",
        "word_to_ix = {t:i+2 for i, t in enumerate(all_words)}\n",
        "\n",
        "word_to_ix['<PAD>'] = 0\n",
        "word_to_ix['<UNK>'] = 1\n",
        "\n",
        "# The tagset is simplified (NE categories not included) \n",
        "tag_to_ix = {'<PAD>':0, 'B-MISC':1, 'B-LOC':1, 'B-ORG':1, 'B-PER':1,\n",
        "             'I-MISC':2, 'I-PER':2, 'I-ORG':2, 'I-LOC':2, 'O':3}\n",
        "ix_to_tag = {0:'<PAD>', 1:'B', 2:'I', 3:'O'}\n",
        "\n",
        "## If we wanted to consider tags in their entirety:\n",
        "# all_tags = list(set([tag for sent_tag in train_data for tag in sent_tag[1]]))\n",
        "# tag_to_ix = {t:i+1 for i, t in enumerate(all_tags)}\n",
        "# tag_to_ix['<PAD>'] = 0\n",
        "# ix_to_tag = {v: k for k, v in tag_to_ix.items()}\n",
        "print(\"Vocab Size:\", len(word_to_ix))\n",
        "print(\"Number of labels:\", len(tag_to_ix))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab Size: 26885\n",
            "Number of labels: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WZuAnmVilza",
        "colab_type": "text"
      },
      "source": [
        "## Dataset class and Dataloading\n",
        "---\n",
        "\n",
        "<font size=\"4\">The standard way to represent a dataset in PyTorch is through the `utils.data.Dataset` class. In order to define your dataset, your custom class should inherit from `Dataset` and override the following two methods:\n",
        "    \n",
        "1. `__len__` which returns the size of the dataset  \n",
        "2. `__getitem__` which receives an index `i`, returning the representation for the i*th* sample in the dataset  \n",
        "\n",
        "You can define other arbitrary methods depending on your specific requirements.         \n",
        "    \n",
        "<font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ5P-gPUjhRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This class representa the dataset.\n",
        "class CoNLL2003NER(Dataset):\n",
        "\n",
        "    def __init__(self, X, max_len, word_to_ix, tag_to_ix):\n",
        "        self.X = X\n",
        "        self.max_len = max_len\n",
        "        self.word_to_ix = word_to_ix\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        \n",
        "    def transform(self, seq, to_ix):\n",
        "        \"\"\"Transorm and prepare one data instance\"\"\"\n",
        "        idxs = [to_ix[w] if w in to_ix else 1 for w in seq]\n",
        "        if len(idxs) >= self.max_len:\n",
        "            # Truncating\n",
        "            idxs = idxs[:self.max_len]    \n",
        "        else:\n",
        "            # Padding\n",
        "            idxs += [0]*(self.max_len-len(seq))\n",
        "        # torch.long tensors are usually used for indexing \n",
        "        return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the length of the dataset\"\"\"\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Given an index, return its corresponding item in the dataset\"\"\"\n",
        "        return self.transform(self.X[idx][0],self.word_to_ix), \\\n",
        "               self.transform(self.X[idx][1], self.tag_to_ix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9DaIIs4rn4H",
        "colab_type": "text"
      },
      "source": [
        "<font size=\"4\"> In order to iterate over a `Dataset` instance, PyTorch provides the `torch.utils.data.DataLoader` which offers the following functionalities:\n",
        "\n",
        "1.   create batches of data to be fed to a network \n",
        "2.   shuffling the data instances \n",
        "3.   loading instances using the multiprocessing workers \n",
        "    <font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6kv5mDemXfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Depending on the batch size, `drop_last` might be set to `True` in order to drop the final smaller batch.\n",
        "\n",
        "params = {'batch_size': BATCH_SIZE,\n",
        "          'shuffle': False,\n",
        "          'num_workers': 6,\n",
        "          'drop_last':True}\n",
        "\n",
        "params_test = {'batch_size': 1, # batch is set to 1 not to drop any instances here\n",
        "          'shuffle': False,\n",
        "          'num_workers': 6,\n",
        "          'drop_last':True}\n",
        "\n",
        "train_data = CoNLL2003NER(train_data, MAX_LEN, word_to_ix, tag_to_ix)\n",
        "train_data_generator = DataLoader(train_data, **params)\n",
        "\n",
        "dev_data = CoNLL2003NER(dev_data, MAX_LEN, word_to_ix, tag_to_ix)\n",
        "dev_data_generator = DataLoader(dev_data, **params)\n",
        "\n",
        "test_data = CoNLL2003NER(test_data, MAX_LEN, word_to_ix, tag_to_ix)\n",
        "test_data_generator = DataLoader(test_data, **params_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXPwobRmmXdf",
        "colab_type": "code",
        "outputId": "ae39c798-94aa-43b0-98eb-66d113835700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "train_data.__getitem__(19)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([10708, 12198, 26100, 18416, 13438, 14566,  2765,  9345,  7023, 17193,\n",
              "         23107,  9652, 20289,  4921, 23027, 15969, 19673, 22432,  2110,  7993,\n",
              "         20703,   336, 25120, 12198, 24663,  9506, 23638, 10373, 26442, 22312,\n",
              "         19339, 11702,  2765, 25717, 21456, 14566, 14999, 24987, 16186, 26638,\n",
              "         18402,  2765, 16981, 14566, 18375,  9756, 16186,  6330,  6858, 23027,\n",
              "          9652, 10752, 14566,  7358, 19297,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0]),\n",
              " tensor([1, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 3, 3, 3,\n",
              "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 1, 2, 3, 1,\n",
              "         2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_P8G0y54rpr8",
        "colab_type": "text"
      },
      "source": [
        "## Define the Model\n",
        "\n",
        "<font size=\"4\"> In PyTorch, models are defined by creating classes that inherit from `torch.nn.Module`. Defining a model involves two critical steps:\n",
        "    \n",
        "\n",
        "1.   Specifying the components of the model in the `__init__` constructor\n",
        "2.   Outlining the way these components interact in the `forward` method\n",
        "  </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Gm5mWQlmXbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A simple LSTM Tagger\n",
        "class LSTMTagger(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size, max_len):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        \n",
        "        # load weights from pre-trained vectors or with random initialization\n",
        "        if not USE_PRETRAINED:\n",
        "            self.word_embeddings = nn.Embedding(vocab_size, embedding_dim) \n",
        "        else: \n",
        "            # load weights from pre-trained vectors \n",
        "            self.word_embeddings = nn.Embedding.from_pretrained(embedding_matrix, freeze=True)\n",
        "            \n",
        "        \n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, dropout=LSTM_DROPOUT)\n",
        "    \n",
        "   \n",
        "        # The linear layer that maps from hidden space to tag space\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, sentence): \n",
        "        embeds = self.word_embeddings(sentence)     # SHAPE: [BATCH_SIZE,MAX_LEN,WORD_EMBEDDING_DIM]\n",
        "        \n",
        "        lstm_out, _ = self.lstm(embeds)\n",
        "\n",
        "        tag_space = self.hidden2tag(lstm_out)\n",
        "        tag_scores = F.log_softmax(tag_space, dim=-1) \n",
        "        \n",
        "        return tag_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBoxn3i6mXX_",
        "colab_type": "code",
        "outputId": "9cb4e84a-0b79-4481-f350-b2bfb7220119",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(ix_to_tag), MAX_LEN).to(device)\n",
        "\n",
        "# The negative log likelihood loss. \n",
        "# It is useful to train a classification problem with C classes.\n",
        "loss_function = nn.NLLLoss(ignore_index=0)  \n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001) \n",
        "\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTMTagger(\n",
            "  (word_embeddings): Embedding(26885, 300)\n",
            "  (lstm): LSTM(300, 200, batch_first=True, dropout=0.3)\n",
            "  (hidden2tag): Linear(in_features=200, out_features=4, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oG8FVrcmXMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write an early stopping procedure\n",
        "\n",
        "def early_stop(losses, patience):\n",
        "    \"\"\"stop execution if there is consecutive decline/stagnation in the loss values.\n",
        "       patience determines how quickly we take action. \n",
        "    \"\"\"\n",
        "    stop = False\n",
        "    patience += 1\n",
        "    if len(losses)>patience and min(losses[-patience:])==losses[-patience]:\n",
        "        stop = True\n",
        "    return stop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-ZspVZwFLMy",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "\n",
        "<font size=\"4\">In PyTorch, you have control over all the stages of the training, from iteration over the data, to adjusting the gradients, calculating the loss and backpropagation given the computed loss. \n",
        "\n",
        "The training procedure involves two for-loops. The inner loop is over the batches of the data. Here is where per-batch loss is computed and model parameters are updated using an optimizer. \n",
        "\n",
        "The inner loop is composed of the following essential steps:\n",
        "\n",
        "1. Clear the gradients. Remember that gradients accumulate over time. In each batch, they need to be reset.  \n",
        "\n",
        "2. Run forward pass and generate an output. \n",
        "\n",
        "3. Pass the output and the gold-standard training labels to the loss function to estimate the degree of deviation from the true labels.   \n",
        "\n",
        "4. Call the `backward()` method on the loss object. This will compute gradients $\\frac{\\partial loss}{\\partial x}$ for every parameter x whose `requires_grad` is set to `True`. In order words, the backward method `back propagates` gradients to each parameter.\n",
        "\n",
        "5. Perform parameter updates by calling `optimizer.step()`. The optimizer is dependent on the computed gradients to perform this operation. \n",
        "\n",
        "The outer loop repeats the inner one for the specified number of epochs. Note that the training procedure should happen in the `training` mode which is set in the beginning of the outer loop.   <font>\n",
        "  \n",
        "### Validation\n",
        "<font size=\"4\"> In each iteration of the training, we can monitor how well the model is learning, by testing it on the hold-out validation data. It is important to set the model mode to `eval` in order to avoid updating the parameters. This is to ensure the model is not overfitting on the training data or find the best parameters for the model. <br />\n",
        "\n",
        "We record all the epoch-based validation and training losses to be able to plot the changes over time.  \n",
        "<font>\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnB2nxhJmXC_",
        "colab_type": "code",
        "outputId": "202a4d8f-8859-4235-da44-da72b1c1e942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "def trainer(model, epochs):\n",
        "    \"\"\"train the model for the specified # of epochs\"\"\"\n",
        "    \n",
        "\n",
        "    batch_losses = []\n",
        "    valid_losses = []\n",
        "    \n",
        "    avg_train_losses = []\n",
        "    avg_valid_losses = [] \n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "                ################\n",
        "                ## train mode ##\n",
        "                ################\n",
        "        model.train() # set the model to training mode  \n",
        "        print('Epoch:', epoch+1)\n",
        "        t0 = time.time()\n",
        "        \n",
        "        n_correct, n_total = 0, 0\n",
        "         \n",
        "        for sentences, tags in train_data_generator:\n",
        "            sentences, tags = sentences.to(device), tags.to(device)\n",
        "            \n",
        "            # clear gradients \n",
        "            model.zero_grad()\n",
        "\n",
        "            # Run forward pass\n",
        "            predictions = model(sentences)\n",
        "            \n",
        "            # compute the loss, gradients, and update the parameters\n",
        "            predictions = predictions.permute(0,2,1)       # loss presumes labels to come 2nd (hence the permute)\n",
        "            batch_loss = loss_function(predictions, tags)  # This computes average loss over all instances of the batch \n",
        "            batch_losses.append(batch_loss.item())\n",
        "            \n",
        "            # compute number of correct predictions per epoch   \n",
        "            outputs = torch.argmax(predictions, dim=1)        \n",
        "            \n",
        "            n_correct += torch.sum(outputs==tags, dtype=torch.float)\n",
        "            n_total += float(tags.size(0) * tags.size(1))  # denominator: batch_size * max_len (e.g. 100 * 52)\n",
        "            \n",
        "            batch_loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        epoch_acc = n_correct/n_total\n",
        "        epoch_loss = np.average(batch_losses)\n",
        "        avg_train_losses.append(epoch_loss) # for keeping track of avg train losses\n",
        "  \n",
        "                ################\n",
        "                ## eval mode ###\n",
        "                ################\n",
        "        model.eval() # set the model to eval mode\n",
        "        for valid_sentences, valid_tags in dev_data_generator:\n",
        "            valid_sentences, valid_tags = valid_sentences.to(device), valid_tags.to(device)\n",
        "            \n",
        "            # Run forward pass. Note since we are in eval mode, we don't need to set grad to zero  \n",
        "            valid_predictions = model(valid_sentences)\n",
        "            valid_predictions = valid_predictions.permute(0,2,1)\n",
        "            # calculate the average loss \n",
        "            valid_batch_loss = loss_function(valid_predictions, valid_tags)\n",
        "            valid_losses.append(valid_batch_loss.item())\n",
        "            \n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_valid_losses.append(valid_loss)\n",
        "        \n",
        "        t = time.time()\n",
        "        print('epoch loss: {}\\tepoch acc: {}\\tvalid loss:{}\\ttime:{}'.format(epoch_loss, epoch_acc.item(), valid_loss, t-t0))\n",
        "        \n",
        "        \n",
        "    return model, avg_train_losses, avg_valid_losses \n",
        "            \n",
        "model, avg_train_losses, avg_valid_losses = trainer(model, EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "epoch loss: 0.3196106525520756\tepoch acc: 0.1124359741806984\tvalid loss:0.39611362230659714\ttime:5.569199562072754\n",
            "Epoch: 2\n",
            "epoch loss: 0.21614207624198367\tepoch acc: 0.12164036929607391\tvalid loss:0.42682979193211784\ttime:5.5655457973480225\n",
            "Epoch: 3\n",
            "epoch loss: 0.16159431488874057\tepoch acc: 0.12515784800052643\tvalid loss:0.3783753116925557\ttime:5.515851736068726\n",
            "Epoch: 4\n",
            "epoch loss: 0.1271207174783935\tepoch acc: 0.12697309255599976\tvalid loss:0.3326923531701438\ttime:5.55051064491272\n",
            "Epoch: 5\n",
            "epoch loss: 0.10389065657400517\tepoch acc: 0.12793026864528656\tvalid loss:0.3027657705645012\ttime:5.488117218017578\n",
            "Epoch: 6\n",
            "epoch loss: 0.08756657087395947\tepoch acc: 0.128306582570076\tvalid loss:0.283835137313656\ttime:5.508924245834351\n",
            "Epoch: 7\n",
            "epoch loss: 0.07563696033846727\tepoch acc: 0.12841518223285675\tvalid loss:0.27187347409869983\ttime:5.507715225219727\n",
            "Epoch: 8\n",
            "epoch loss: 0.06657709801725332\tepoch acc: 0.12845559418201447\tvalid loss:0.2634918226682959\ttime:5.572537183761597\n",
            "Epoch: 9\n",
            "epoch loss: 0.05948474625887742\tepoch acc: 0.128468856215477\tvalid loss:0.2578117060326491\ttime:5.594451427459717\n",
            "Epoch: 10\n",
            "epoch loss: 0.05377570313814273\tepoch acc: 0.12847326695919037\tvalid loss:0.25416611427404356\ttime:5.533544063568115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa4vzoEReMeB",
        "colab_type": "code",
        "outputId": "8501905d-9db9-4079-dccc-5727c44bdbed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        }
      },
      "source": [
        "# Visualizing the loss as the network trained\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "\n",
        "plt.plot(range(1,len(avg_train_losses)+1),avg_train_losses, label='Training Loss')\n",
        "plt.plot(range(1,len(avg_valid_losses)+1),avg_valid_losses,label='Validation Loss')\n",
        "\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "\n",
        "# find position of lowest validation loss\n",
        "minposs = avg_valid_losses.index(min(avg_valid_losses))+1 \n",
        "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping')\n",
        "\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAFzCAYAAADSXxtkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd3gU1f7H8ffJpkJCElqAJHQInQAB\nBLwaBBFEwYqAKKgIFkTs5doLdq9XxZ+C2AuiXhUURUBWlN5BSiDUANIJEKlJzu+PDRIQNEB2Jtl8\nXs+zT7KzM3u+HIXPnClnjLUWERERCSxBbhcgIiIihU8BLyIiEoAU8CIiIgFIAS8iIhKAFPAiIiIB\nSAEvIiISgILdLqCwlC9f3lavXt3tMlz3xx9/ULp0abfLCHjqZ2eon52hfnZIbq6vr6OiCu0r586d\nu91aW+FEnwVMwFevXp05c+a4XYbrvF4vqampbpcR8NTPzlA/O0P97JzC7mtjzLqTfaZD9CIiIk54\n4w2qfP21Y80FzAheRESkSBs9moqZmY41pxG8iIhIAFLAi4iIBCAFvIiISABSwIuIiAQgXWQnIiLi\nBK+XBV4vqQ41pxG8iIhIAFLAi4iIOOHFF0n87DPHmtMhehERESd8+y3ldB+8iIiInAkFfCDZupzg\nw1luVyEiIkWADtEHgu3pMOlxWDaGFuFx0LQ2VKzndlUiIuIijeCLs71b4Ns7YFgrSJ8EbQbhyTkI\nIzvBqsluVyciIvlFRJATFuZYcxrBF0cH98K012Da65BzEFKuh3PvhciKzLVNabPqZfj4Cuj6MrTo\n63a1IiIC8P33LHbwPngFfHGSfQjmvgc/Pwf7tkPDS+G8h6FcrT9XORheEW4YD59fB2MHw85V0OEx\nCNLBGhGRkkQBXxzk5sLSr2DSk7BrDVT/F5z/OMS3OPH64dHQezR8fw9M/S/sXA2XDofQUs7WLSIi\nRz35JNXWrIHUVEeaU8AXdat/homPwqb5ULEhXP0F1O4Ixvz9dp5g3yH6crVh/L9hd1foNQqi4pyp\nW0REjjVpErEO3gevgC+qNv/mC/b0iVAmAS55E5r0gCBPwb/DGGhzK8RWhy/7w9sdoPdnENfQb2WL\niEjRoBOzRU3mevjfQHjzbNgwB85/Em6bC8m9Ti3c86vXFa77HnKzYeQFsHJi4dYsIiJFjgK+qNi3\n03co/bUWsOQraDcYbl/g+xkSfubfXyUZ+k/yjeY/uRJmv33m3ykiIkWWDtG77fB+mPkm/PIfOLQX\nmvaG9g9AdELhtxUdD9d/D1/cAN/dBTtWQ6cnT//IgIiIFFy5chzOzXWsOQW8W3JzYMEnMHko7N0E\ndTtDh0chroF/2w2Lgl6fwvgHYcYw31X5l42AsEj/tisiUtJ9+SVLdB98ALMWVvwAEx+DbcshPgUu\nfxuqt3OuhiAPdHkOytaCH+6Dd7v4Lr4rU8W5GkRExK90Dt5JGbPh3Qvh056Qcxh6fAD9Jzob7vm1\nHgC9PvPdJz+iA/y+yJ06RERKggceoMaIEY41p4B3wvaV8FkfGNkRdqT77k+/dSY06P7P97P7W91O\ncP0Pvjre6QxpP7hbj4hIoJo+neglSxxrTgHvT3s3w9ghMKy17+Ev7f8Ng+dDyxvAE+J2dUdVagw3\n/gTl68CoXjDj/3ynEkREpNjSOXh/OLAHpr0K04dBziFo2R/OuQciK7hd2clFVYLrxsH/BsAP98OO\nVdD5Wd+MeCIiUuzoX+/ClH0I5rwDU56HfTug4WXQ4WEoW9PtygomtDT0+BAmPuJ7Wt2utXDFOxBe\nxu3KRETkFCngC0NuLiz5H/z0pC8Ua5wDHR+H+OZuV3bqgoKg01O+nZLv7vadl+/9GcQkul2ZiEjx\nlpDAwRDnTs/69Ry8MaazMSbNGJNujLn/b9a73BhjjTEp+ZY9kLddmjHmAn/WeUZWe2FEe/jyBgiN\nhKu/hGvHFM9wzy/lerj6c9id4ZvDfuM8tysSESnePvqIZf/+t2PN+S3gjTEeYBjQBWgA9DLG/GUW\nF2NMFHA7MDPfsgZAT6Ah0Bl4I+/7io7fF8GHl8EH3X2H4y99Cwb+AnUK8KS34qJ2B7jhR/CE+W7v\nWzbW7YpERKSA/DmCbwWkW2tXW2sPAaOA7idY70ngOeBAvmXdgVHW2oPW2jVAet73uW/XOt+FaG+d\nA5vmQaenYdAcaNrTd3g70FSsDzdO8j2B7rNrYOqrusJeROR0DBlC7ddfd6w5f56Djwcy8r3fALTO\nv4IxpjmQaK39zhhzz3Hbzjhu23h/FVog+3bClBdh9ggwQXD2EGg3BCJiXC3LEZEVod+38NVNMOFh\n2LkKLnyxaN3qJyJS1C1YQGRJeB68MSYIeBnodwbfMQAYABAXF4fX6y2U2vILyjlIwoaxVF3/JZ6c\nA2yudB5rq/fiYHB5mLmg0Ns7U1lZWX7pBwAq9KVG1WCqzX2PnasXsKThveQEl/ZPW0WcX/tZ/qR+\ndob62RnJmZnk5OQ41tf+DPiNQP5LrxPylh0RBTQCvMZ3zroSMMYY060A2wJgrR0ODAdISUmxqamp\nhVd9TjYs/AQmP+N7GEzShdDhESpXrE/lwmul0Hm9Xgq1H47X/jyY356yY2/nX2lPQO/REFvNf+0V\nUX7vZwHUz05RPzskJobMzEzH+tqfJ41nA3WMMTWMMaH4Lpobc+RDa+1ua215a211a211fIfku1lr\n5+St19MYE2aMqQHUAWb5sdZj7d0Cb7aDMbf5Htt63fe+J7BVrO9YCUVasz5wzVew93ffFfYZs92u\nSEREjuO3gLfWZgODgPHAMmC0tXaJMeaJvFH63227BBgNLAV+AG611ub4q9a/iKwIlZPhqo98V5FX\na+tY08VGjXOg/yTf5DjvXwRLvnK7IhGRoq1uXfYlJDjWnF/PwVtrxwHjjlv2yEnWTT3u/dPA034r\n7u8YA5e95UrTxUr5OtD/JxjVGz7v53sq3dl3Bs5tgiIihWn4cFZ4vTj1YO4AvK9LHFW6HFz7DTS+\nEiY9Ad8M8k3ZKyIirtJUtXLmQsLhshFQthb8/CxkrvM9675UWbcrExEpOgYMoO6mTRAAF9lJSWIM\ntH8ALh0OGTNh5Pm+Q/YiIuKzYgWlNmxwrDkFvBSuplf5Dtnv2wkjOsC66W5XJCJSIingpfBVawv9\nJ/oO0X/QDRZ97nZFIiIljgJe/KNcLbhhAiS2hv/1B++zmsNeRMRBCnjxn1Jloc//oGlv8D4DXw2E\n7INuVyUi4o7kZLJq13asOV1FL/4VHAqXvAHlasJPT0HmerjqY9/tdSIiJckrr5Du9eLUVDcawYv/\nGQPn3ANXvAMb5/mmt92+0u2qREQCmgJenNPoct9jZw/uhbc7wppf3K5IRMQ5ffpQ/2nnJmhVwIuz\nElvBjZMgMg4+vBQWfOJ2RSIiztiwgbBt2xxrTgEvzoutfvQhPl/fDBMfh1znniUkIlISKODFHREx\n0OdLaNEPfn0ZPu0J+zPdrkpEJGAo4MU9nhC4+L9w0X9g1U++i++2pbldlYhIQFDAi/tSroe+38KB\nPb7pbZeP++dtRESKmzZt2N2woWPNKeClaKjWBgZ4oXxtGNULvM9Bbq7bVYmIFJ5nnmHNjTc61pwC\nXoqO6Hi47oe8me+GwuhrfLfUiYjIKVPAS9ESEu6b+a7zc5D2ve9++R2r3K5KROTMXX45DR95xLHm\nFPBS9BgDZ90E134NWVtheHtYOcHtqkREzsyOHYTs2eNYcwp4KbpqnOM7Lx9TFT6+En55WU+kExEp\nIAW8FG2x1XyT4jS6DCY9Dl9cB4f+cLsqEZEiTwEvRV9oKbh8JJz/BCz9BkZ2gl1r3a5KRKRIU8BL\n8WAMtLsdrv4cdmfA8FRY7XW7KhGRguvQgV3NmzvWnAJeipfaHeHGyRBZyfewmunDdF5eRIqHhx9m\n3bXXOtacAl6Kn3K1oP8EqNcVxj8IXw2Ew/vdrkpEpEhRwEvxFBYFV34A7R+CRaPhnQsgM8PtqkRE\nTq5LFxrfd59jzSngpfgKCoJz74Fen8LONb7z8munul2ViMiJ7d+P5+BBx5pTwEvxl9QF+k+CiFj4\noBvMGqHz8iJS4ingJTBUqAs3TvJdhDfubhhzG2Q7t6csIlLUKOAlcIRHQ89P4Zx7YP6H8F5X2PO7\n21WJiLhCAS+BJSgIznsIenwAW5bC8HMhY5bbVYmIwEUXsaNNG8ea82vAG2M6G2PSjDHpxpj7T/D5\nTcaYxcaYBcaYX40xDfKWVzfG7M9bvsAY86Y/65QA1KA79J8IIRHw7oUw9323KxKRku7uu8m46irH\nmvNbwBtjPMAwoAvQAOh1JMDz+cRa29hamww8D7yc77NV1trkvNdN/qpTAlhcA9+kODX+BWMHw3d3\nQfYht6sSEXGEP0fwrYB0a+1qa+0hYBTQPf8K1tr8z80rDejSZylcpcrC1V/4prmd/TZ80N33CFoR\nEaelppI8ZIhjzfkz4OOB/DOPbMhbdgxjzK3GmFX4RvCD831Uwxgz3xjzszHmX36sUwJdkMf3oJrL\nR8Km+b775TfOc7sqERG/MtZP9wsbY64AOltr++e9vwZoba0ddJL1ewMXWGv7GmPCgEhr7Q5jTAvg\na6DhcSN+jDEDgAEAcXFxLUaNGuWXP0txkpWVRWRkpNtlFFmRe1fT6LdnCD20i7SkW9hS6bzT+h71\nszPUz85QPzsjecgQcnJyWPzaa4X2ne3bt59rrU050Wf+DPg2wGPW2gvy3j8AYK195iTrBwG7rLXR\nJ/jMC9xtrZ1zsvZSUlLsnDkn/bjE8Hq9pKamul1G0fbHDvi8L6z9Bc66Bc5/EjzBp/QV6mdnqJ+d\noX52SGoqmZmZxCxYUGhfaYw5acD78xD9bKCOMaaGMSYU6AmMOa6wOvnedgVW5i2vkHeRHsaYmkAd\nYLUfa5WSpHQ5uOYraH0zzHgDPrrUF/oiIgHk1IYtp8Bam22MGQSMBzzAO9baJcaYJ4A51toxwCBj\nTEfgMLAL6Ju3+TnAE8aYw0AucJO1dqe/apUSyBMCXZ6Fyk1g7BAYkQo9P4FKjd2uTEQCVY8ebF2x\nghiHmvNbwANYa8cB445b9ki+328/yXZfAl/6szYRAJJ7Q/kk+KwPvH0+XDIMGl3udlUiEohuuYVN\nXi91HWpOM9mJJLSAAV6o3BS+uB4mPAq5OW5XJSKBZt8+gg4ccKw5BbwIQFQc9B0LKdfD1Ffg4yth\n/y63qxKRQHLhhTS5/y+TuvqNAl7kiOBQuOg/cNErsGYKDG8PW5e5XZWIyGlRwIscL+U66PcdHN4H\nb3eEZWPdrkhE5JQp4EVOpGpr33n5CnkX4E0eCrm5blclIlJgCniRkylTBfqNg+Q+8PNzMKo3HNjz\nz9uJiBQBCniRvxMSDt1fhwtfhPQJ8HYH2L7S7apEpDjq14/NnTs71pwCXuSfGAOtboRrv4F9O2DE\neVTYOhX8NM2ziAQoBbxIEVX9bBjwM5StQcOlz8PI831X24uIFMT27YTs3u1Ycwp4kVMRkwj9fyKt\n7q2wZxO8fzF8cIkePysi/+yKK2j46KOONaeAFzlVnmB+r9IJbpsHnZ6G3xfCiPYw+lrYtsLt6kRE\nAAW8yOkLCYe2g+D2hXDu/ZA+Cd5oDd/cCpkZblcnIiWcAl7kTIWXgfYP+IK+9c2waDS81hx+eAD+\n2O52dSJSQingRQpL6fLQeajv0H2THjDzTfhvU98kObp/XkQcpoAXKWwxidB9GNwyE2p38E2S89+m\nMO01OLzf7epExC0338zGbt0ca04BL+IvFepCjw98U95WSYYfH4JXm8Pc9yAn2+XiRMRxV13FtvPO\nc6w5BbyIv1VpBtd8BX2/heh4GHs7DGsFv/1P89uLlCQZGYRt3epYcwr4k9i29yD7DmmUJYWoxr/g\nhgnQ81MIDoMvroPh58LKCZoVT6QkuOYa6g8d6lhzCvgT2Lr3AKkvTGbElDVulyKBxhiodyHc9Ctc\nOhwO7IaPr4B3L4T1M9yuTkQCiAL+BCpGhXNuUgXemrKKrXsPuF2OBKIgDzS9CgbN8T3IZucqeOcC\n+OQq2Pyb29WJSABQwJ/EPRfU41B2Lv+dqCeHiR8Fh/oeZDN4PnR4FNZPhzfPhi/7w87VblcnIsWY\nAv4kapQvzdWtqzJqdgbpW7PcLkcCXWhp+Nedvslyzh4Cy76F11vCt3fAnt/drk5EiiEF/N8Y3KEO\nESEenvthudulSEkREQsdH4PbF0CLfjDvA3i1GUx4BPbtdLk4ETkjd91FRo8ejjWngP8b5SLDuDm1\nFhOWbmHWGv3jKg6KqgRdX/Kdo2/QDaa+Cv9NhikvwEEdURIpli6+mB1t2zrWnAL+H1zfrgaVyoQz\ndNwyrG5lEqeVrQGXDYebp0L1dvDTU/BqMsx8C7IPul2diJyKtDQi1q93rDkF/D+ICPVwZ6e6LMjI\nZNzizW6XIyVVXEPo9anvPvoK9eD7e+H1FFjwCeTmuF2diBTEwIEkvfyyY80p4Avg8uYJJMVF8fz4\n5RzK1sxj4qLEVtB3LPT5H0SUha9vhv9rC8vGarIcETmGAr4APEGG+y+sx7od+/h45jq3y5GSzhjf\nQ2wGeOHK930j+M/6wNsdYPXPblcnIkWEAr6AUutWoF3tcrw6aSV7Dhx2uxwRX9A3vARumQHdXoe9\nW+CDbvBBd9g41+3qRMRlCvgCMsbwQJf67Np3mDe9q9wuR+QoTzA0vwZumwsXPAObF8OI83yj+m1p\nblcnIi5RwJ+CRvHRXNosnpG/rmFTpp7rLUVMSDi0ucU3WU7qA7DKC2+cBV/fApnOXbkrIifx0EOs\nu+Yax5rza8AbYzobY9KMMenGmPtP8PlNxpjFxpgFxphfjTEN8n32QN52acaYC/xZ56m4q1NdrIWX\nJ6xwuxSREwuLgtT7fUF/1i2w+At4rQWMGQxrpuiqexG3dOzIrhYtHGvObwFvjPEAw4AuQAOgV/4A\nz/OJtbaxtTYZeB54OW/bBkBPoCHQGXgj7/tclxBbin7tqvPlvA0s3bTH7XJETq50ObjgaRg8D5r2\ngsWfw/sXw0v14Ns7Yc0vCnsRJy1YQGR6umPN+XME3wpIt9auttYeAkYB3fOvYK3Nn5ClgSP3+XQH\nRllrD1pr1wDped9XJNyaWpsy4SE8qylspTiIToBur8I96XDle1CtLSz8FN6/yBf2392lsBdxwpAh\n1H79dceaC/bjd8cDGfnebwBaH7+SMeZW4E4gFDgv37b5H469IW/Z8dsOAAYAxMXF4fV6C6PuAulS\n1TAqbRuvfzGJRuWLxMEFALKyshzth5Kq+PZzLFS8jqByvSi3Yy4Vtk2l3NwP8Mx+m0MhMWyr0IZt\nFdqRGdMAisBBs+Lbz8WL+tkZyZmZ5OTkONbX/gz4ArHWDgOGGWN6Aw8BfU9h2+HAcICUlBSbmprq\nlxpPpM3ZOfz60s+M2xjCLZedTVCQcaztv+P1enGyH0qqwOjnzr4fh/6AlT8SuuRr4leMJ37T91C6\nom8O/AaX+Eb8Qe6EfWD0c9GnfnZITAyZmZmO9bU/D9FvBBLzvU/IW3Yyo4BLTnNbx4UFe7jngiSW\n/r6HrxcUqdJETk1oaWh4KfR4H+5dlXcYvw3M//jYw/hrf9VhfJFixJ8BPxuoY4ypYYwJxXfR3Jj8\nKxhj6uR72xVYmff7GKCnMSbMGFMDqAPM8mOtp+XiJlVoHB/Ni+PTOHBY//BJAPgz7D/whf0V7x4N\n+/e6wsv14bu7FfYixYDfDtFba7ONMYOA8YAHeMdau8QY8wQwx1o7BhhkjOkIHAZ2kXd4Pm+90cBS\nIBu41Vpb5P41CQoyPHBhPXqPmMl709Zy07m13C5JpPCEloZGl/leh/6AFeNh6dcw/yOYPQIi46B+\nN99selXbuHYYX6TYGDqU1fPm0dyh5vx6Dt5aOw4Yd9yyR/L9fvvfbPs08LT/qiscbWuV57x6FRk2\nOZ2rUhKJLR3qdkkihS9/2B/MgpU/wpKvFPYip6JtW/YcOuRYc5rJrhDc36UefxzM5vXJzt3fKOKa\nsEhf0F/1oe/WuyvegcTWvrA/5jD+VB3GF8lv2jTK/PabY825fhV9IKgbF0WPlEQ+mL6Wvm2qU7Vc\nKbdLEnFGWCQ0utz3OpgFK8fDkq9h/odHR/YNuvuuxq96lkb2UrI9+CA1MzNh0CBHmtMIvpDccX5d\nPEGGF37Uwz2khDoS9ld9CPesOjqyn/cBvHehb2Q/7h6N7EUcohF8IYkrE86N/6rJaz+l0//sGjRN\njHG7JBH3nHBk/5Uv7GcNh8hKR++z18hexC80gi9EA8+tRbnSoQwdtwxr7T9vIFIS/Dmy/8g3sr98\nJCS2zDeyb+Ab2a+bBrm5blcrEjA0gi9EkWHBDOlYh4e/WcJPy7fSoX6c2yWJFC1hkdD4Ct/rYBas\n+MF3693xI/uGl0LiWW5XK1KsKeALWc9WVXl36lqe+X4559atQLBHB0lETuiYsN/ru8/+uMP4daOa\nQvRGiG8B5etCkP4+STH2yiukz5lDikPNKeALWYgniHs71+Omj+by+dwN9GpV1e2SRIq+sKgThn3F\nlZPgm/G+dUKjoEqyL+yPvMpUAVM0ngMh8o+Sk8nKzHSsOQW8H1zQMI6UarG8PGEF3ZOrUCpU3SxS\nYPnC/tfJP5HaKB42zj36mj4Mcg/71o2slBf2zX0/qzSDCF3gKkXUxInELlwIDj1sRsnjB8YYHriw\nPpf/3zRGTFnD7R3r/PNGIvJXJggqJPleyb19yw4fgC2/HRv6ad8d3aZcnWNH+ZUaQXCYO/WL5PfU\nU1TLzIS77nKkOQW8n7SoFkuXRpV4a8oqereuSoUo/QMjUihCwiEhxfc6Yv8u2DQ/L/DnwaqfYNEo\n32dBIVCp8bGhX662zudLwFPA+9G9nesxYekW/jtpBU9d0tjtckQCV0Qs1DrP9wKwFvZszDfKnwcL\nP/XNrgcQVsZ3OP+Y8/mV3atfxA8U8H5Uo3xprm5dlY9mrqdf2xrUrhjpdkkiJYMxEJ3gezXo7luW\nmwPbVxx7aH/aq5Cb7fs8qsrRc/nxzX07AOHR7v0ZRM6QAt7PbutQhy/nbeT5H5Yz/Fqnbo4Qkb8I\n8kDF+r5Xsz6+ZYf3w+bFx4b+8m+PblO+br5RfnOI0/l8KT4U8H5WPjKMm86tyYs/rmDWmp20qlHW\n7ZJE5IiQCEhs5XsdsW8nbJrnO6y/cS6kT/Qd3gfwhP71fH7ZWjqfLwXz1lukzZxJa4eaU8A74Iaz\na/LhjHUMHbeMr25pi9F9uyJFV6myULuj7wW+8/m7M449nz//I99kPABh0RCf73x+5WTdny8nlpTE\n/t9/d6w5BbwDIkI93HV+Evd+uYjvf9vMhY11MY9IsWEMxFT1vRpe6luWkw3b044G/sa58OsrYPOe\nkhdSGsrV9F2tn/9VtqZvB0JKprFjKbd4se6DDzSXt0hg5K9reO6H5XSsH0dosA7piRRbnmCIa+h7\nNb/Wt+zQPt/5/M2LYEc67FgFmxbA0m/A5nuITkTZfKFf6+jPsjUhtLQ7fx5xxksvkZiZCQ8+6Ehz\nCniHeIIM919Yj+venc0nM9fRr10Nt0sSkcIUWgqqtva98ss+BLvW5oV+Ouxc5Qv/1ZNh4SfHrlsm\n/mjol611dEcgthp4Qhz7o0hgUMA7KLVuBdrWKserP6VzWYsEyoTrL6xIwAsOhQp1fa/jHcw6Gvg7\nVh3dCfjtSziw++h6xgOx1fON+vOFf1QVXeQnJ6SAd5AxhgcvrM9Fr/3Km95V3Nu5ntsliYibwiKh\nclPfKz9rfVfz78wX+kcO+6+ZAtn7j64bHHH0EP/x5/xLldXFfiWYAt5hjeKjuSS5CiN/XcM1bapR\nOTrC7ZJEpKgxBkqX873y38IHkJsLe38/NvR3pMPWpZA27ujEPeCbqOeY0M93+D9ME28FOgW8C+7q\nlMS4xZt5+ccVvHBl03/eQETkiKAgiI73vWqee+xnOYchc/1fR/1rp8Kiz45dN7LSn6GfmAks2gqR\ncRBVGaIq+Z7qp9F/4frwQ5ZNn04bh5pTwLsgsWwp+rWrzohfVnP92TWoX7mM2yWJSCDwhBw9R88F\nx352aB/sXH3shX470mH5t9TatwNWv3/s+iGlfEEfVTlf8OfbAYispB2BU5WYyMFVqxxrTgHvkltT\na/PZ7Aye/X4571/f6p83EBE5E6GlfI/OrdToLx/9MnEc/2paG7I2w97NvlMAe7fk/dwMvy+AFT/A\n4X1//d6Q0icO/j9feTsI2hGAzz6jwpIlug8+0EWXCmFQ+9o8PW4Zv67cztl1yrtdkoiUUDnBpU5+\npf8R1sLBvUd3ALLy7QAceW2a7/t50h2BfMEfmW8HIOq4UwOB6v/+j/jMTHjiCUeaU8C76Nq21Xh/\n+lqe+X4ZY2udTVBQCd+7FZGiyxgIL+N7/eOOwJ6jRwBOtCOwcZ7vZ/67AY44fkfgmFME+ZYH8o5A\nIVHAuygs2MM9FyRx+6gFfLNwI5c2S3C7JBGRM2OM7+r98OhT2xHYu/mvpwj+dkegFETEQniMr62I\nmKPt/mXZce9DI0vE6QIFvMsublKFEb+s5sXxK+jSqDLhIR63SxIR8b9T3hHIdwQga7NvB+BApm9C\noP2ZkJkBBxb73h/c8w9te462fbKdgGPeH7csOLRw+8JPFPAuCwryTX7Te8RM3p+2loHn1nK7JBGR\nouOYHYGkgm2Tm+ML+gO7j90JyP/++GV7NuW9z4ScQ3///SGl/n6n4GQ7CvnnKHCAAr4IaFurPO2T\nKvD65HR6pCQSW7p47B2KiBRJQR7fLH6n++S+w/tPvBPw5/vMY3cU9myCrcvylu0B7Im/96xcfk8a\nTMxp/8FOjV8D3hjTGfgv4AHettY+e9zndwL9gWxgG3C9tXZd3mc5wOK8Vddba7v5s1a33d+lPl3+\nO4XXJ6fz8EUN3C5HRKTkConwvaIqnfq2ubm+UwQnOVqwe3e5wq/3JPz2hAJjjAcYBnQBGgC9jDHH\nJ9d8IMVa2wT4Ang+32f7rbXJea+ADneApEpRXNkikQ+mryVj5wluMRERkaIvKMh3OD62mu8ZAzXO\ngfoXQ/NrYEUkMT8vdK4UPy3d8JMAACAASURBVH53KyDdWrvaWnsIGAV0z7+CtXaytfZIms0ASvRl\n5HecXxdPkOGF8WlulyIiIoXtvfeo9MMPjjXnz0P08UBGvvcbgNYnWRfgBuD7fO/DjTFz8B2+f9Za\n+/XxGxhjBgADAOLi4vB6vWdas+vOr+phzMJNNCu1kxrRp35FfVZWVkD0Q1GnfnaG+tkZ6mdnJGdm\nkpOT41hfFyjgjTG3A+8Ce4G3gWbA/dbaHwujCGNMHyAFyP/khGrW2o3GmJrAT8aYxdbaYybxtdYO\nB4YDpKSk2FSHpv/zpxZnHWbaC15+2FyKUd3OwpzivZper5dA6IeiTv3sDPWzM9TPDomJITMz07G+\nLugh+uuttXuATkAscA3w7N9vwkYgMd/7hLxlxzDGdAT+DXSz1h48stxauzHv52rAi2+nIuBFhYdw\ne8c6zFyzk8lpW90uR0REiqmCBvyRYeSFwIfW2iX5lp3MbKCOMaaGMSYU6AmMOeZLjWkGvIUv3Lfm\nWx5rjAnL+7080A5YWsBai71erapSo3xpnhm3nOycXLfLERGRYqigAT/XGPMjvoAfb4yJAv42eay1\n2cAgYDywDBhtrV1ijHnCGHPkqvgXgEjgc2PMAmPMkR2A+sAcY8xCYDK+c/AlJuBDPEHc1zmJlVuz\n+GLuBrfLERGRwjBuHIue/aeD34WnoBfZ3QAkA6uttfuMMWWB6/5pI2vtOGDcccseyfd7x5NsNw1o\nXMDaAtIFDSvRolosL09YQbfkKpQK1ZxEIiLFWqlS5IaHO9ZcQUfwbYA0a21m3gVxDwG7/VeWGGN4\n8MJ6bN17kLd/WeN2OSIicqbeeIMqX//lhjC/KWjA/x+wzxjTFLgLWAV84LeqBIAW1crSuWEl3vp5\nFdv2HvznDUREpOgaPZqKDt6OWNCAz7bWWnwT1bxurR0G6GG8Dri3cxIHs3P576QVbpciIiLFSEED\nfq8x5gF8t8d9Z4wJAkL8V5YcUbNCJL1bV+XTWRms2pbldjkiIlJMFDTgrwIO4rsffjO+e9pf8FtV\ncozBHeoQEeLh+R+Wu12KiIgUEwUK+LxQ/xiINsZcBByw1uocvEPKR4Zx07k1Gb9kC7PX7nS7HBER\nKQYKFPDGmB7ALOBKoAcw0xhzhT8Lk2PdcHZN4sqEMXTcMnyXQ4iISLHi9bLglVcca66gh+j/DbS0\n1va11l6L70lxD/uvLDleRKiHO8+vy/z1mfzw22a3yxERkSKuoAEflH8qWWDHKWwrheSKFonUjYvk\nuR+WcyhbU9iKiBQrL75I4mefOdZcQUP6B2PMeGNMP2NMP+A7jpuhTvzPE2R4oEt91u7Yx6ez1rtd\njoiInIpvv6Xc9OmONVfQi+zuwfdY1iZ5r+HW2vv8WZicWGpSBdrULMd/J61kz4HDbpcjIiJFVIEP\ns1trv7TW3pn3+sqfRcnJ+aawrc/OPw7x1s+r3C5HRESKqL8NeGPMXmPMnhO89hpj9jhVpByrcUI0\n3ZOr8PYva/h99363yxERkSLobwPeWhtlrS1zgleUtbaMU0XKX93dKQlr4eUfNYWtiEixEBFBTliY\nY83pSvhiKrFsKfq2rcYX8zawfLMOpoiIFHnff8/i555zrDkFfDF2a/vaRIUF8+z3msJWRESOpYAv\nxmJKhXLbeXXwpm1javp2t8sREZG/8+STVPvAuVneFfDF3DVtqhEfE8HQccvIzdUUtiIiRdakScTO\nm+dYcwr4Yi48xMM9FySxZNMexizc5HY5IiJSRCjgA0C3plVoFF+GF8ancShHo3gREVHAB4SgIMOD\nXeqzMXM/36RrdjsREVHAB4y2tcvTIyWB79Yc5sXxaXqkrIhIUVOuHIfLODeFTLBjLYnfPXNZEzZv\n3szrk9PZfziHh7rWxxjjdlkiIgLw5Zcs8XpJdag5BXwA8QQZ+jUMpWbVBEb+uoYDh3N4snsjgoIU\n8iIiJY0CPsAEGcOjFzcgPMTDmz+v4sDhXJ6/ogkehbyIiLseeIAa69dDaqojzSngA5Axhvs6JxER\n4uE/E1dwMDuH/1yVTIhHl1yIiLhm+nSiMzMda04BH6CMMdzesQ7hIUE88/1yDmbn8nrvZoQFe9wu\nTUREHKAhXYAbeG4tHu/WkAlLt9D//TnsP5TjdkkiIuIABXwJ0LdtdZ6/vAm/pm/nuvdmkXUw2+2S\nRETEzxTwJUSPlom8clUys9fu4tqRM9m9XxPiiIg4KiGBgxUqONacXwPeGNPZGJNmjEk3xtx/gs/v\nNMYsNcYsMsZMMsZUy/dZX2PMyrxXX3/WWVJ0T45nWO9mLN64m6vfnsHOPw65XZKISMnx0Ucs+/e/\nHWvObwFvjPEAw4AuQAOglzGmwXGrzQdSrLVNgC+A5/O2LQs8CrQGWgGPGmNi/VVrSdK5UWWGX5PC\nii1Z9Bo+g617D7hdkoiI+IE/R/CtgHRr7Wpr7SFgFNA9/wrW2snW2n15b2cACXm/XwBMsNbutNbu\nAiYAnf1Ya4nSvl5F3u3XkvU799HzrRn8vnu/2yWJiAS+IUOo/frrjjXnz4CPBzLyvd+Qt+xkbgC+\nP81t5RS1q12eD29oxda9B+nx1nQydu77541EROT0LVhAZHq6Y80VifvgjTF9gBTg3FPcbgAwACAu\nLg6v11v4xRUzWVlZp9QPdzYP5qU5++n+qpd7W4ZTqbSuuyyIU+1nOT3qZ2eon52RnJlJTk6OY33t\nz4DfCCTme5+Qt+wYxpiOwL+Bc621B/Ntm3rctt7jt7XWDgeGA6SkpNhUh6b/K8q8Xi+n0g+pwFkt\n93DNyJm8OD+Xj/u3JKlSlL/KCxin2s9yetTPzlA/OyQmhszMTMf62p/DtdlAHWNMDWNMKNATGJN/\nBWNMM+AtoJu1dmu+j8YDnYwxsXkX13XKWyZ+0KBKGT4beBaeIOg5fDq/bdztdkkiInKG/Bbw1tps\nYBC+YF4GjLbWLjHGPGGM6Za32gtAJPC5MWaBMWZM3rY7gSfx7STMBp7IWyZ+UrtiFKMHtqFUaDC9\nRsxg3vpdbpckIhJY6tZlX0LCP69XSPx6Dt5aOw4Yd9yyR/L93vFvtn0HeMd/1cnxqpUrzeib2tB7\nxAyueXsmI/u15Kya5dwuS0QkMAwfzgqvlyoONacrquQY8TERjB7YhsoxEfR9ZxY/r9jmdkkiInIa\nFPDyF3FlwvlswFnUrBDJje/PYcLSLW6XJCJS/A0YQN0XX3SsOQW8nFC5yDBG3XgW9auU4eaP5vLt\nok1ulyQiUrytWEGpDRsca04BLycVXSqEj25oRbOqMQz+dD5fzHXuf0wRETkzCnj5W1HhIbx/fSva\n1CrH3Z8v5KMZ69wuSURECkABL/+oVGgwI/u25Lx6FXno698Y+esat0sSEZF/oICXAgkP8fBmnxZ0\naVSJJ79dyrDJzs2nLCISEJKTyapd27HmFPBSYKHBQbzWqxmXJFfhhfFpvDg+DWut22WJiBQPr7xC\n+qBBjjVXJB42I8VHsCeIl3okEx7i4fXJ6ew/nMNDXetjjHG7NBERyUcBL6fME2QYemljwkM8jPx1\nDQcO5/Bk90YEBSnkRUROqk8f6m/ZAg49bEYBL6clKMjw6MUNfOfmf17FgcO5PH9FEzwKeRGRE9uw\ngbDMTMeaU8DLaTPGcF/nJCJCPPxn4goOZufwn6uSCfHo0g4REbcp4OWMGGO4vWMdwkOCeOb75Rw4\nnMuwq5sRFuxxuzQRkRJNQy0pFAPPrcXj3RoycdkW+r8/h/2HctwuSUSkRFPAS6Hp27Y6z1/ehF/T\nt3Pde7PIOpjtdkkiIkVHmzbsbtjQseYU8FKoerRM5JWrkpm9dhfXjJzJ7v2H3S5JRKRoeOYZ1tx4\no2PNKeCl0HVPjmdY72b8tnE3vUfMYOcfh9wuSUSkxFHAi190blSZ4deksHJrFr2Gz2Dr3gNulyQi\n4q7LL6fhI4841pwCXvymfb2KvNuvJet37qPnWzP4ffd+t0sSEXHPjh2E7NnjWHMKePGrdrXL8+EN\nrdi69yA93ppOxs59bpckIlIiKODF71Kql+Xj/q3Zsz+bK9+czuptWW6XJCIS8BTw4oimiTF8euNZ\nHM7JpcdbM0jbvNftkkREApoCXhzToEoZPht4Fp4g6Dl8Or9t3O12SSIizunQgV3NmzvWnAJeHFW7\nYhSjB7ahVGgwvUbMYO66XW6XJCLijIcfZt211zrWnAJeHFetXGlG39SGsqVDuWbkTLxpW90uSUQk\n4CjgxRXxMRGMHtiGhNgI+r07m9tHzWfrHt0rLyIBrEsXGt93n2PNKeDFNXFlwhkz6GwGd6jD94s3\n0+Gln3l36hqyc3LdLk1EpPDt34/n4EHHmlPAi6vCQzzceX5dxt9xDs2qxfL42KV0e30q89br3LyI\nyJlQwEuRUKN8ad6/riVvXN2cnX8c4rI3pnH/l4vYpXnsRUROiwJeigxjDBc2rszEu85lwDk1+Xzu\nBs57ycuoWevJzbVulyciUqwo4KXIiQwL5sEL6zNu8L+oUzGK+/+3mMvfnMaSTbpvXkSKsYsuYkeb\nNo4159eAN8Z0NsakGWPSjTH3n+Dzc4wx84wx2caYK477LMcYsyDvNcafdUrRlFQpis8GnsVLVzYl\nY+c+Ln7tVx4bs4Q9B/SMeREphu6+m4yrrnKsuWB/fbExxgMMA84HNgCzjTFjrLVL8622HugH3H2C\nr9hvrU32V31SPBhjuLxFAh3rx/Hij2m8P30t3y3+nYe61qdb0yoYY9wuUUSkSPLnCL4VkG6tXW2t\nPQSMArrnX8Fau9ZauwjQfVHyt6JLhfDkJY345tZ2VIkO5/ZRC+g9YibpWzWnvYgUE6mpJA8Z4lhz\nfhvBA/FARr73G4DWp7B9uDFmDpANPGut/fr4FYwxA4ABAHFxcXi93tOvNkBkZWUFfD/c3tDiLRPK\nFyt2cMF/ptC5egjdaoUQFuzcaL4k9HNRoH52hvrZGcmZmeTk5DjW1/4M+DNVzVq70RhTE/jJGLPY\nWrsq/wrW2uHAcICUlBSbmprqQplFi9frpST0w3nA4KyDPPv9cr6Yu4EFu4J55OL6dGoQ58hh+5LS\nz25TPztD/eyQmBgyMzMd62t/HqLfCCTme5+Qt6xArLUb836uBrxAs8IsToq/8pFhvHhlUz6/qQ1R\n4cEM/HAuN7w/h/U79rldmoiI6/wZ8LOBOsaYGsaYUKAnUKCr4Y0xscaYsLzfywPtgKV/v5WUVC2r\nl2XsbWfzUNf6zFy9g/P/8zOvTlrJgcM5bpcmIuIavwW8tTYbGASMB5YBo621S4wxTxhjugEYY1oa\nYzYAVwJvGWOW5G1eH5hjjFkITMZ3Dl4BLycV4gmi/79qMumuVDo2iOPlCSvo/MoUpqzY5nZpIiI+\nPXqw1cFTIX49B2+tHQeMO27ZI/l+n43v0P3x200DGvuzNglMlaLDGda7OT1bbuORb5Zw7Tuz6Nq4\nMg9dVJ/K0RFulyciJdktt7DJ66WuQ81pJjsJSP+qU4EfhvyLu86vy8RlW+jw0s+MmLKaw3pSnYi4\nZd8+gg4491hsBbwErLBgD7d1qMPEO8+lTc1yPD1uGRe9+iuz1ux0uzQRKYkuvJAm9/9lUle/UcBL\nwEssW4qR/Voy4toUsg5m0+Ot6dw5egHbs5x7LrOIiNMU8FJinN8gjol3nsut7WsxduEmznvRy4cz\n1pGjJ9WJSABSwEuJEhHq4Z4L6vH97efQKD6ah7/+jUvfmMrCjEy3SxMRKVQKeCmRaleM5OP+rXm1\nVzM27z7AJW9M5d9fLWb3Pj2pTkQCgwJeSixjDN2aVmHSXedyXdsafDprPee95OXzORlYq8P2IlLI\n+vVjc+fOjjWngJcSLyo8hEcubsDY286mWrlS3PPFInq8NZ3lm/e4XZqIBBIFvIg7GlaJ5oub2vL8\n5U1I35pF11d/5alvl5J1MNvt0kQkEGzfTsju3Y41p4AXyScoyNCjZSI/3ZVKj5RERk5dQ4eXvHy7\naJMO24vImbniCho++qhjzSngRU4gtnQoz1zWmP/d3JbykWEM+mQ+174zi9XbstwuTUSkQBTwIn+j\nWdVYxgw6m8e7NWTB+kw6v/ILL/2YxqEcjeZFpGjz68NmRAKBJ8jQt211ujSuxDPjlvPaT+mUCYU+\nh5fTq1VVEsuWcrtEEZG/0AhepIAqRoXzn6uSGT2wDbViPLz58yrOeWEy1707i0nLtmhGPBEpUjSC\nFzlFrWqU5fbm4dRNbs2o2RmMmrWeG96fQ3xMBL1bV6VHSiIVosLcLlNEipqbb2bjkiXEONScRvAi\np6lKTAR3nl+Xqfefx/9d3Zzq5Uvxwvg02j47iUGfzGP6qh268l5EjrrqKradd55jzWkEL3KGQjxB\ndGlcmS6NK7N6WxYfz1zPF3M38O2i36ldMZKrW1flsuYJREeEuF2qiLgpI4OwrVsda04jeJFCVLNC\nJA9f1ICZD3bgxSubEhkWzONjl9J66ETu/WIhizbooTYiJdY111B/6FDHmtMIXsQPwkM8XNEigSta\nJPDbxt18PHMdX8/fxOg5G2iSEE2f1tW4uGkVIkI9bpcqIgFKI3gRP2sUH80zlzVh5r878Hi3huw/\nlMO9Xy6i9dCJPD52CelbNXmOiBQ+jeBFHFImPIS+batzbZtqzF67i49mrOOjGet4d+pazqpZlj5n\nVaNTg0qEBmu/W0TOnAJexGHGGFrVKEurGmXZntWA0XMy+GTmegZ9Mp/ykWH0bJlIz1aJJMRqAh0R\nOX0KeBEXlY8M45bU2tx0Ti1+XrmNj2es4w1vOm9402mfVJE+Z1XjnLoV8AQZt0sVkTN1111kLF7s\n2H3wCniRIiAoyNA+qSLtkyqyMXM/n85cz6jZGUx6bzYJsUcn0CkfqQl0RIqtiy9mR1SUY83pZJ9I\nERMfE8HdFyQx7f7zeL13MxJjS/H8D2m0eWYSgz+dz8zVmkBHpFhKSyNi/XrHmtMIXqSICg0O4qIm\nVbioSRXSt2bx8cx1fDF3A2MWbqJuXCRXt67Gpc3jKROuCXREioWBA0nKzIRrr3WkOY3gRYqB2hUj\nefTihsx6sCPPX96E8BAPj45ZQuunJ3H/l4v4beNut0sUkSJGI3iRYiQi1EOPlon0aJnIog2ZfDxj\nPV8v2Mio2Rk0TYyhT+uqXNy0CuEhmkBHpKTTCF6kmGqSEMNzVzRh5oMdefTiBvxxMJt7vlhE66GT\nePLbpazepgl0REoyjeBFirnoiBCua1eDfm2rM3PNTj6asY4Ppq9l5K9raFurHH3Oqsb5DeII8Wh/\nXqQkUcCLBAhjDGfVLMdZNcuxbe/BPyfQueXjeVSMCuPS5vF0qBdH86oxBCvsRZz30EOsW7gwMJ4H\nb4zpbIxJM8akG2PuP8Hn5xhj5hljso0xVxz3WV9jzMq8V19/1ikSaCpEhXFr+9pMubc9I/um0LBK\nGUb+soYeb02n+ZMTuPXjeXw+J4Otew+4XapIydGxI7tatHCsOb+N4I0xHmAYcD6wAZhtjBljrV2a\nb7X1QD/g7uO2LQs8CqQAFpibt+0uf9UrEog8QYYO9ePoUD+OPQcOM3Xldrxp25ictpXvFv8OQKP4\nMrRPqkhqUkWSE2M0a56IvyxYQGR6OqSmOtKcPw/RtwLSrbWrAYwxo4DuwJ8Bb61dm/dZ7nHbXgBM\nsNbuzPt8AtAZ+PRUCjh8+DAbNmzgwIGSM0qJjo5m2bJlbpdxRsLDw0lISCAkRPd3F6Yy4SF0aVyZ\nLo0rY61l6e978KZtw5u2lWGT03ntp3RiSoVwTp0KtK9XgXPqVKCcZs4TKTxDhlA7MxP693ekOX8G\nfDyQke/9BqD1GWwbf/xKxpgBwACAuLg4vF7vMZ9HRkYSFxdHfHw8xpSMUUlOTg4eT/G9Rcpay+7d\nu1m4cCFZWUX3KvCsrKy//P9WHDU00LAe/FGrFEu257BwWw7eZZsYs3ATBqgRHUSTCh6alPdQPTqI\nIIf/HgVKPxd16mdnJGdmkpOT41hfF+uL7Ky1w4HhACkpKTb1uMMey5YtIyEhocSEO8DevXuJcnCu\nY3+IiooiKyuLlJQUt0s5Ka/Xy/H/vxV3XfN+5uZalmzaw+S0rUxO28o3qzL5Ov0w5UqHcm7dCqTW\nq8g5dcoTUyrU7zUFYj8XRepnh8TEkJmZ6Vhf+zPgNwKJ+d4n5C0r6Lapx23rPZ0iSlK4Bwr9N3NX\nUJChcUI0jROiGdyhDjv/OMQvK7cxeflWvCu28b/5Gwky0KxqLKl1K9C+XkUaVC5DkM7dixQp/gz4\n2UAdY0wNfIHdE+hdwG3HA0ONMbF57zsBDxR+if61Y8cOOnToAMDmzZvxeDxUqFABgFmzZhEaevIR\n0Jw5c/jggw949dVX/7aNtm3bMm3atDOu1ev18uKLL/Ltt9+e8XdJYClbOpTuyfF0T44nJ9eyaEMm\nk9O28XPaVl6asIKXJqygQlQYqXUrkJpUkbPrlCc6QtdPiLjNbwFvrc02xgzCF9Ye4B1r7RJjzBPA\nHGvtGGNMS+ArIBa42BjzuLW2obV2pzHmSXw7CQBPHLngrjgpV64cCxYsAOCxxx4jMjKSu+8+esNA\ndnY2wcEn/k+QkpJSoEPUhRHuIgXlCTI0qxpLs6qx3Hl+XbZnHWTKim1MTtvGj0u38PncDXiCDC2q\nxZKaVIH2SRWpVylKR2VEAIYOZfW8eTR3qDm/noO31o4Dxh237JF8v8/Gd/j9RNu+A7zjz/rc0K9f\nP8LDw5k/fz7t2rWjZ8+e3H777Rw4cICIiAjeffddkpKSjhlRP/bYY6xfv57Vq1ezfv16hgwZwuDB\ngwHfhYRHLpB57LHHiImJYfny5bRo0YKPPvoIYwzjxo3jzjvvpHTp0rRr147Vq1cXeKT+6aefMnTo\nUKy1dO3aleeee46cnBxuuOEG5syZgzGG66+/njvuuINXX32VN998k+DgYBo0aMCoUaP82ZVSBJSP\nDOOy5glc1jyB7JxcFm7IZPJy3214z/+QxvM/pFGpTDipSUdH95FhxfrSH5HT17Ytew4dcqy5EvM3\n7fGxS1i6aU+hfmeDKmV49OKGp7zdhg0bmDZtGh6Phz179vDLL78QHBzMxIkTefDBB/nyyy//ss3y\n5cuZPHkye/fuJSkpiZtvvvkvt5HNnz+fmTNnUrduXdq1a8fUqVNJSUlh4MCBTJkyhRo1atCrV68C\n17lp0ybuu+8+5s6dS2xsLJ06deLrr78mMTGRjRs38ttvvwGQmZkJwLPPPsuaNWsICwv7c5mUHMGe\nIFpUK0uLamW5+4Iktu45gHeF7za87xb9zqjZGYR4DCnVytK+nm90X7tipEb3UnJMm0aZ334LiPvg\n5SSuvPLKP29l2717N3379mXlypUYYzh8+PAJt+natSthYWGEhYVRsWJFtmzZQkLCsQc/WrVqRXx8\nPEFBQSQnJ7N27VoiIyOpWbMmNWrUAKBXr14MHz68QHXOnj2b1NTUP68buPrqq5kyZQoPP/wwq1ev\n5rbbbqNr16506tQJgCZNmnD11VdzySWXcMkll5xW30jgqFgmnB4pifRISeRwTi7z1u1ict5990PH\nLWfouOXEx0T8eSi/be1ylArVP0kSwB58kJqZmTBokCPNlZi/Tacz0vaX0qVL//n7ww8/TPv27fnq\nq69Yu3btSW+fCAs7OuGIx+MhOzv7tNYpDLGxsSxcuJDx48fz5ptvMnr0aN555x2+++47pkyZwtix\nY3n66adZvHjxSa8xkJIlxBNE65rlaF2zHPd3qcfvu/f/OcnO1/M38vHM9YR6gmhdsyypSRVJTapA\nzfKl//mLReSk9K+vy3bv3k18vG8On/fee6/Qvz8pKYnVq1ezdu1aqlevzmeffVbgbVu1asXgwYPZ\nvn07sbGxfPrpp9x2221s376d0NBQLr/8cpKSkujTpw+5ublkZGTQvn17zj77bEaNGkVWVhYxMU49\nVkGKk8rREfRqVZVerapyKDuXOWt34l3huxXvyW+X8uS3ULVsKWqVPsS2yAySE2OoWSFS0+iKnAIF\nvMvuvfde+vbty1NPPUXXrl3/eYNTFBERwRtvvEHnzp0pXbo0LVu2POm6kyZNOuaw/+eff86zzz5L\n+/bt/7zIrnv37ixcuJDrrruO3FzfDMPPPPMMOTk59OnTh927d2OtZfDgwQp3KZDQ4CDa1i5P29rl\nefDC+mzYte/P0f3UlVuZ/MUiACLDgmkUX4amiTEkJ8TQNDGGytHhOocvchLGWut2DYUiJSXFzpkz\n55hly5Yto379+i5V5I4TzWSXlZVFZGQk1lpuvfVW6tSpwx133OFShQVT1P/baeYvZ/w0eTJVG7Zk\n0YZMFmZksmDDbpZt2sOhHN/OZYWoMJomxNA0IZqmiTE0TYghupTuwT9V+v/ZIampZGZmEpN3+3Rh\nMMbMtdae8J5qjeBLgBEjRvD+++9z6NAhmjVrxsCBA90uSaRAgoyhdsVIaleM5LLmvqNLB7NzWP77\nXhZuyGRhxm4Wbshk4rItf25To3xpmiZE0yRvlN+wShnCQ4rv8xkkgLzyCulz5uDUJNwK+BLgjjvu\nKPIjdpGCCgv2+EbriTHQxrdsz4HD/LZhNwvyRvozVu/k6wWbAAgOMtSrHOUb6eeN8mtX1Pl8cUFy\nMlkO3kKsgBeRYq9MeMif5/GP2LLnAAszMv8c6Y9ZuImPZ64HoFSoh8bx0STn7Sg0SYgmPiZC5/PF\nvyZOJHbhQt0HLyJyJuLKhNOpYSU6NawE+J6St3bHH38G/oKMTN6duvbP8/nlI0OPjvITfef1nXhi\nnpQgTz1FtcxMuOsuR5pTwItIiRAUZKhZIZKa/9/enYdHUacJHP++SUiaHISjk8gRDWdcHEggCGMY\nkctjFAUcIDArJDLDCOg64o4u+PAooO54IOvMrKB4BBQEBCEDDrq6CB4zzAAicmmWBDMaRJIQQjok\nnfO3f3SnyUVESHdDRhDJtgAAFLNJREFU5f08T57uqq6ueqt46PdXv6r6vVHhjB/gup5fUVXDV98X\nu8/0T/PFt0V8mJlH7b3HV3UK9ST9xNhIrukSqdfz1WVDE7xSqtUKDgqgf7f29O/WnqnueQ5nJQeO\nnXbdwPdtEbtzCtn8het6fmCAEB8T4Un4CbHt6R0dodfz1SVJE7wXjRgxgrlz53LzzTd75j3//PNk\nZmaybNmyJr8zfPhwFi9ezKBBg7j11lt58803Gz1P3lRluoYyMjLo06cPffv2BeDRRx9l2LBhjB49\n+qL2ScvKKquLsLUhuaed5J5nr+fnFTs9Z/hf5Bbxl/3fsWaX63p+2zau6/kJ7oTfr2sksR1CCdCk\nr/xME7wXTZkyhbVr19ZL8GvXruWZZ545r+9v3br1hxc6h4yMDMaMGeNJ8IsWLbrgdSnV2kW3s3Fj\nXxs39o0Bzl7P35/rupb/RW4RK3f+k4pPvgYgJCiAHlGux/t61b5GhxNnDyUkSLv4lW9ogveiCRMm\nMH/+fCoqKggODiYnJ4fvvvuO66+/nlmzZrF7927KysqYMGECCxcubPT9uLg49uzZg91u58knn2Tl\nypVER0cTGxtLUlIS4HrGffny5VRUVNCrVy+WLl3KgQMH2Lx5Mx999BFPPPEEb7/9No8//jhjxoxh\nwoQJbNu2jd/97ndUVVVx7bXXsmzZMkJCQoiLiyM1NZUtW7ZQWVnJ+vXrufrqq89rX7WsrGpN6l7P\nHzfANdR0RVUNmd87OPTdabLySsjKL+Hzb06xxd29DxAgcFWnMHpGhdGzQfKPsOkAPZb30ktk/uMf\nDPHR5lpPgn93Lnx/oGXXeUU/+PlT5/y4Y8eODB48mHfffZexY8eydu1aJk2ahIjw5JNP0rFjR6qr\nqxk1ahT79++nf//+Ta7ns88+Y+3atezbt4+qqioGDhzoSfB33nknM2bMAGD+/Pm8/vrrPPTQQ9xx\nxx2ehF6X0+kkLS2Nbdu20adPH6ZNm8ayZct44IEHALDb7ezdu5elS5eyePFiXnnllR88DFpWVinX\n9fx+3SLp1y2y3vyyimqy80vIzi8hK+/s60f/l09l9dmRRGPahdQ74+/pfo2KCNHH96wiPp6y48d9\ntrnWk+D9pLabvjbBv/rqqwC89dZbLF++nKqqKo4fP87hw4fPmeA/+eQTxo8fT2hoKAB33HGH57OD\nBw8yf/58ioqKKCkpYeTIkc3Gk5mZSffu3enTpw8AqampvPDCC54Ef+eddwKQlJTExo0bz2sftays\nUufWNjiQn3SN5Cdd6yf+quoaviks9ZztZ+WVkJ1Xwtt7j1FSfrYSZDtbUKOz/V7R4XTrEKo3911u\ntmyh04ED+hx8i2vmTNubxo4dy5w5c9i7dy+lpaUkJSXx9ddfs3jxYnbv3k2HDh1IS0vD6XRe0PrT\n0tLIyMggISGBFStW8MEHH1xUvLUlZ1ui3KyWlVXq3IICAzzd/DfVmW+M4URxuSvx5zk8yX97Zj7r\nP8v1LBccFEAPe1i9s/1e0eF0t4fpo3yXqueeI7aoCB55xCeb019VLwsPD2fEiBFMnz6dKVOmAFBc\nXExYWBiRkZGcOHGCd999t9lCD8OGDSMtLY158+ZRVVXFli1bPOPJOxwOOnfuTGVlJatXryY6OhqA\niIgIHA5Ho3XFx8eTk5NDVlYWvXr14o033uCGG264qH3UsrJKtRwR4YpIG1dE2vhZb3u9z06XVpKV\n73B39Z8hK6+E/bmn+cuB455n9wMEYjuGnu3qr3PW306v87cqmuB9YMqUKYwfP95zM1lCQgIDBgzg\n6quvJjY2lqFDhzb7/YEDB5KSkkJCQgLR0dH1Sr4+/vjjDBkyhKioKIYMGUJhYSEAkydPZsaMGfzx\nj39kw4YNnuVtNhvp6elMnDjRc5PdzJkzf9T+aFlZpfwjMrQNSVd1JOmqjvXmOyurOZp/pl5Xf1Ze\nCZ8cKfCM1Aeu6nsNu/p7RbsqTSrr0XKxFtNUudjL0aX+b6flNX1Dj/PFqa4xfNvgOn9tA8BR5zq/\nLRDioiLo1iGUbh3auv9c72M7hNKubZDe6NcStFysUkqplhAYIMTZw4izhzGaGM98Ywx5jnLXmX5+\nCR9/nglhbck9VcrO7ALOVFTXW09ESBBd6yR9bQBcHjTBK6VUKyMixLSzEdPORnIvO1eW5zB8uOvS\nnzGG02WV5J4qI/dUqfu19r02AC7KG2/w5c6dtVWOvU4TvFJKKQ8RoX1oMO1Dgxs92gfaALgosbGU\nZ2f7bHOa4JVSSp03bQBchHXriDp0SJ+DV0opdfnxXQOgrecyQ1RECG0CA3y1ixdu2TK6FhWBj2qD\naIJXSinlM95oAAB0Cgsmup2NmHYhxETYiG4X4pqOCCGmnWvaHn6ZNARaiCZ4LwsMDKRfv36e6cmT\nJzN37tzz/v75lIata9euXTzyyCOUl5dTXl5OSkoKCxYsYMeOHQQHB5OcnPyj9+GHJCcn87e//a3F\n16uUan1+TAMgz+HkRHE5J4pdr/nu6cPfFVNQUk6Nabhu6BQWQky7EKI9ib9+oyCmnY1OYcEEWaAh\noAney9q2bcu+C3zm8UKGip05cyYbNmwgISGB6upqMjMzAdfzxOHh4V5J8JrclVK+UrcBAI0bALWq\nqmsoPFNxtgHgqN8IOFHs5MCxYk6eKafhcDABAvbwEFfCjzjbCIiOcDcG3D0CncJCLul6AJrg/WTR\nokVs2bKFsrIykpOTeemllxARhg8fTmJiIp9++qlnaFuA7OxsJk6cyN69ewE4cuQIKSkpnulaBQUF\ndO7cGXD1HvTt25ecnBxefPFFAgMDWbVqFX/605+IjY1l+vTpFBQUEBUVRXp6OldeeSVpaWnYbDb2\n7NlDcXExS5YsYcyYMaxYsYJNmzZx+vRpjh07xl133cVjjz0GuIbjLSkpYceOHSxYsAC73c7BgwdJ\nSkpi1apViAhbt27lwQcfJCwsjKFDh3L06FHeeecdHx1tpVRrExQYQLT7DL3fDzQECkoq3L0ATvIc\n5eS5ewROOJwcP+3ki9wiCkoqGn03MECwhwe7En5E042A6AhXj0CAHxoCrSvBN3Xn4qRJMHs2lJbC\nrbc2/jwtzfVXUAANSq+yY8cPbrKsrIzExETP9Lx580hJSeG+++7j0UcfBWDq1Km888473H777QBU\nVFRQOyrfggULAOjZsyeRkZHs27ePxMRE0tPTufvuuxttb/bs2cTHxzN8+HBuueUWUlNTiYuLY+bM\nmfW6+m+//XZSU1NJTU3ltdde4/777ycjIwOAnJwcdu3aRXZ2NiNGjCArKwtwdf8fPHiQ0NBQrr32\nWm677TYGDao/gNLnn3/OoUOH6NKlC0OHDuWvf/0rgwYN4p577uHjjz+me/fu9RouSinlT0GBAZ6x\n/5tTUVVDQUk5eQ7X2b+nEeBuFOSeKmXvN6coPNO4IRAUIERFhNDz5w8xKrqcxr/c3uHVBC8itwB/\nAAKBV4wxTzX4PAR4HUgCTgIpxpgcEYkDvgQy3Yv+3Rjz4wZMv0Scq4t++/btPPPMM5SWllJYWMg1\n11zjSfApKSlNruvXv/416enpLFmyhHXr1rFr165Gy8ydO5fp06fz/vvv8+abb7JmzRp2NNEQ2blz\np6cc7NSpU3n44Yc9n02aNImAgAB69+5Njx49+OqrrwC48cYb6dSpE+AqK/vpp582SvCDBw/2jFOf\nmJhITk4O4eHh9OjRg+7duwOusfmXL1/e7HFTSqlLSXBQAF3at6VL+7bNLldRVUN+Sf1GQN17BWo6\nlPgoYi8meBEJBF4AbgRygd0istkYc7jOYr8CThljeonIZOBpoDa7ZRtjEmlJzZ1xh4Y2/7ndfl5n\n7OfD6XQye/Zs9uzZQ2xsLAsWLKhXLjYsLKzJ7/3iF79g4cKFjBw5kqSkJE+ybahnz57MmjWLGTNm\nEBUVxcmTJ39UfA2fN62dPtf8umrLzULLlJxVSqnLSXBQAF3bt6VrUw2BFSv46u9fwbhRPonFm7cJ\nDgayjDFHjTEVwFpgbINlxgIr3e83AKPEEqMZNK82mdvtdkpKSupVe2uOzWbj5ptvZtasWU12zwO8\n9957nspQR44cITAwkPbt2zcqH5ucnOypbrd69Wquv/56z2fr16+npqaG7Oxsjh49Snx8PAAffPAB\nhYWFlJWVkZGR8YNV8GrFx8dz9OhRcnJyAFi3bt15fU8ppSxlxQqueO89n23Om130XYFv60znAkPO\ntYwxpkpETgO1p6XdReRzoBiYb4z5pOEGROQ3wG8AYmJiGnVFR0ZGNlkT3ZfKysro37+/Z3r06NEs\nXLiQadOm0bdvX2JiYkhMTKS8vByHw0F1dTVnzpzxxF1eXk6bNm080+PGjWPjxo1cd911Te7bmjVr\nmDdvHqGhoQQFBfHyyy9TWlrKiBEjmDZtGps2beLZZ5/l97//PbNnz+bpp5/GbrezdOlSHA4HlZWV\ndO7cmUGDBnlusqusrMTpdDJw4EDGjRvHsWPHSElJIT4+3hODw+GgtLSUqqoqz7yKigqcTidVVVU8\n99xz3HTTTYSFhTFw4EAqKyub/bdxOp1NXlq4VNTeVKi8S4+zb+hx9o3EoiKqq6t9d6yNMV75Aybg\nuu5eOz0V+O8GyxwEutWZzgbsQAjQyT0vCVcjoF1z20tKSjINHT58uNG8y92zzz5r5s+ff87Pi4uL\nL2r9qampZv369Y3mp6enm3vvvfeC1+twOIwxxtTU1JhZs2aZJUuWNLv8pf5vt337dn+H0CrocfYN\nPc4+csMN5lRCQouuEthjzpEXvXkGfwyIrTPdzT2vqWVyRSQI10ONJ91BlwMYYz4TkWygD7CHVmz8\n+PFkZ2fz4Ycf+juUH+3ll19m5cqVVFRUMGDAAO655x5/h6SUUpbmzQS/G+gtIt1xJfLJwC8bLLMZ\nSAV24jrj/9AYY0QkCig0xlSLSA+gN3DUi7FeFjZt2uT1baxYsaLJ+WlpaaSlpV3weufMmcOcOXMu\n+PtKKaV+HK8leOO6pn4f8D+4HpN7zRhzSEQW4epS2Ay8CrwhIllAIa5GAMAwYJGIVAI1wExjTKG3\nYlVKKaW8butW9n/8McN8tDmvPgdvjNkKbG0w79E6753AxCa+9zbwdgvFYI0yg62IaThupFJKWUFo\nKDW25gfUaUmX/2j6zbDZbJw8eVITxmXEGMPJkyex+fA/gVJK+cTSpXRxjxjqC5YeqrZbt27k5uaS\nn5/v71B8xul0XvbJ0WazeUbDU0opy3jrLaKLiny2OUsn+DZt2niGR20tduzYwYABA/wdhlJKKT+z\ndBe9Ukop1VppgldKKaUsSBO8UkopZUFilTvMRSQf+Ke/47gE2IECfwfRCuhx9g09zr6hx9l3WvpY\nX2WMiWrqA8skeOUiInuMMYN+eEl1MfQ4+4YeZ9/Q4+w7vjzW2kWvlFJKWZAmeKWUUsqCNMFbz3J/\nB9BK6HH2DT3OvqHH2Xd8dqz1GrxSSillQXoGr5RSSlmQJngLEJFYEdkuIodF5JCI/NbfMVmZiASK\nyOci8o6/Y7EyEWkvIhtE5CsR+VJErvN3TFYkInPcvxsHRWSNiFzexSwuESLymojkicjBOvM6isgH\nInLE/drBmzFogreGKuDfjTF9gZ8C94pIXz/HZGW/Bb70dxCtwB+A94wxVwMJ6DFvcSLSFbgfGGSM\n+QkQCEz2b1SWsQK4pcG8ucA2Y0xvYJt72ms0wVuAMea4MWav+70D1w9hV/9GZU0i0g24DXjF37FY\nmYhEAsOAVwGMMRXGGN+V4WpdgoC2IhIEhALf+TkeSzDGfAwUNpg9Fljpfr8SGOfNGDTBW4yIxAED\ngH/4NxLLeh54GKjxdyAW1x3IB9Ldl0NeEZEwfwdlNcaYY8Bi4BvgOHDaGPO+f6OytBhjzHH3+++B\nGG9uTBO8hYhIOPA28IAxptjf8ViNiIwB8owxn/k7llYgCBgILDPGDADO4OXuzNbIfQ14LK4GVRcg\nTETu8m9UrYNxPcLm1cfYNMFbhIi0wZXcVxtjNvo7HosaCtwhIjnAWmCkiKzyb0iWlQvkGmNqe6I2\n4Er4qmWNBr42xuQbYyqBjUCyn2OyshMi0hnA/ZrnzY1pgrcAERFc1yq/NMYs8Xc8VmWMmWeM6WaM\nicN1I9KHxhg92/ECY8z3wLciEu+eNQo47MeQrOob4KciEur+HRmF3szoTZuBVPf7VODP3tyYJnhr\nGApMxXVGuc/9d6u/g1LqIv0bsFpE9gOJwH/6OR7LcfeQbAD2Agdw5QQd1a4FiMgaYCcQLyK5IvIr\n4CngRhE5gqv35CmvxqAj2SmllFLWo2fwSimllAVpgldKKaUsSBO8UkopZUGa4JVSSikL0gSvlFJK\nWZAmeKWUV4jIcK24p5T/aIJXSimlLEgTvFKtnIjcJSK73AMkveSud18iIv/lrhO+TUSi3Msmisjf\nRWS/iGyqrWctIr1E5H9F5AsR2SsiPd2rD69T0321e7Q0ROQpETnsXs9iP+26UpamCV6pVkxE/gVI\nAYYaYxKBauBfgTBgjzHmGuAj4DH3V14H/sMY0x/XyGe181cDLxhjEnCNZV5bMWsA8ADQF+gBDBWR\nTsB44Br3ep7w7l4q1TppgleqdRsFJAG7RWSfe7oHrnK469zLrAJ+5q7R3t4Y85F7/kpgmIhEAF2N\nMZsAjDFOY0ype5ldxphcY0wNsA+IA04DTuBVEbkTqF1WKdWCNMEr1boJsNIYk+j+izfGLGhiuQsd\n07q8zvtqIMgYUwUMxjUG+hjgvQtct1KqGZrglWrdtgETRCQaQEQ6ishVuH4bJriX+SXwqTHmNHBK\nRK53z58KfGSMcQC5IjLOvY4QEQk91wZFJByINMZsBeYACd7YMaVauyB/B6CU8h9jzGERmQ+8LyIB\nQCVwL3AGGOz+LA/XdXpwlbh80Z3AjwJ3u+dPBV4SkUXudUxsZrMRwJ9FxIarB+HBFt4tpRRaTU4p\n1QQRKTHGhPs7DqXUhdMueqWUUsqC9AxeKaWUsiA9g1dKKaUsSBO8UkopZUGa4JVSSikL0gSvlFJK\nWZAmeKWUUsqCNMErpZRSFvT/LpKSjMyCBxEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B4YGlBUVEF-",
        "colab_type": "text"
      },
      "source": [
        "## Test\n",
        "<font size=\"4\">\n",
        "  Now you can compute the performance of the model on the unseen test data.\n",
        "  \n",
        "  </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9XRK1GJSjBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define evaluation metrics (acc, precision, recall, and f1-score)\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "class Evaluate():\n",
        "    def __init__(self, out, labels):\n",
        "        self.out = out.numpy().flatten()\n",
        "        self.labels = labels.numpy().flatten()\n",
        "    def accuracy(self):\n",
        "        nb_correct = sum(y_t==y_p for y_t, y_p in zip(self.labels, self.out))\n",
        "        nb_true = len(self.labels)\n",
        "        score = nb_correct / nb_true\n",
        "        return score\n",
        "    def precision_recall_fscore(self, tag_list, average='macro'):\n",
        "        return precision_recall_fscore_support(self.labels, self.out, \n",
        "                                                  average=average,labels=tag_list)[:-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tWDZVOimW6L",
        "colab_type": "code",
        "outputId": "08ac4117-c55d-40fc-b95c-dc360b865de2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# evaluate the model on test set \n",
        "\n",
        "\n",
        "all_preds = torch.LongTensor().to(device)\n",
        "all_labels = torch.LongTensor().to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for sent, target in test_data_generator:\n",
        "        sent, target = sent.to(device), target.to(device)\n",
        "        tag_scores = model(sent)\n",
        "        \n",
        "        predict = tag_scores.data.max(2, keepdim=True)[1]        \n",
        "        all_preds = torch.cat([all_preds, predict])\n",
        "        all_labels = torch.cat([all_labels,target])\n",
        "    \n",
        "    all_preds, all_labels = all_preds.cpu(), all_labels.cpu()\n",
        "    all_preds = all_preds.squeeze(dim=-1)\n",
        "    evaluator = Evaluate(all_preds, all_labels)\n",
        "    print('Overall Results on the Test set:')\n",
        "    print('Accuracy\\t{}'.format(evaluator.accuracy()))\n",
        "    pr, rc, fm = evaluator.precision_recall_fscore(tag_list=[1,2,3]) # we ignore pad  \n",
        "    print('Precision\\t{}\\nRecall\\t\\t{}\\nF1-score\\t{}'.format(pr,rc,fm))\n",
        "    \n",
        "    print('\\n==================\\n')\n",
        "    \n",
        "    print('# Results ignoring PAD and O:\\n')\n",
        "    tag_list = [1,2] # we ignore both pad and O\n",
        "    pr, rc, fm = evaluator.precision_recall_fscore(tag_list)\n",
        "    print('Precision\\t{}\\nRecall\\t\\t{}\\nF1-score\\t{}'.format(pr,rc,fm))         "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall Results on the Test set:\n",
            "Accuracy\t0.11162282893674604\n",
            "Precision\t0.5982770033898029\n",
            "Recall\t\t0.7745626739983061\n",
            "F1-score\t0.5573810746713709\n",
            "\n",
            "==================\n",
            "\n",
            "# Results ignoring PAD and O:\n",
            "\n",
            "Precision\t0.8479220083363301\n",
            "Recall\t\t0.666072009744719\n",
            "F1-score\t0.74606962207045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6EP7vrK45xK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-k0ILVz45vD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp4BAe_k45pB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERszEw8wPRma",
        "colab_type": "text"
      },
      "source": [
        "# * TO DO #1  \n",
        "## Early Stopping\n",
        "- End training if validation losses stagnate/increase \n",
        "- Save the best Model \n",
        "\n",
        "Hint: Have a quick look at this page to learn how to save/load models: https://bit.ly/2D7byMe "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooaEokG3QUl6",
        "colab_type": "text"
      },
      "source": [
        "# * TO DO #2\n",
        "## Load pre-trained embbeding\n",
        "\n",
        "Fill embedding_matrix\n",
        "\n",
        "wv_file = embed_folder + FILE_NAME\n",
        "\n",
        "wv_model = gensim.models.KeyedVectors.load_word2vec_format(wv_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbw1WYYlRWZ6",
        "colab_type": "text"
      },
      "source": [
        "# * TO DO #3\n",
        "## Add other layers or components to the Model\n",
        "\n",
        "e.g. bi-directional LSTM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oft6CzDGJeOt",
        "colab_type": "text"
      },
      "source": [
        "# * TO DO #4: Character Embedding\n",
        "\n",
        "<font size=\"4\"> \n",
        "*    Out-of-vocabulary (OOV) words are an issue in word embeddings that can negatively affect performance. For this reason it is helpful to have character-level features that can augment word representation. \n",
        "    \n",
        "*    In some applications, sub-word units can provide helpful clues for the learning models. For these reasons, character embeddings are sometimes used in conjuction with word-level features. \n",
        "\n",
        "    \n",
        "The overall process for creating combined word and character embeddings is depicted in the image below:\n",
        "    \n",
        "<figure>\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1PiHd5B18-TH8vdpX62E6Sae4nUXmf6sD\" />\n",
        "<figcaption>word and character features</figcaption></center>\n",
        "</figure>\n",
        "  \n",
        "\n",
        "Consider the word <i>gene</i>. The procedure is captured in more detail in the following diagram:\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1Zigj71mnsUqjcnona3BvKS6PCugVFIVe\" \n",
        "     width=\"400\" height=\"400\"/>\n",
        "<figcaption>source: https://www.aclweb.org/anthology/N18-1131</figcaption></center>\n",
        "</figure>\n",
        "    \n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxQdoOfN2-no",
        "colab_type": "text"
      },
      "source": [
        "<font size=\"4\"> \n",
        "Similarly, in this exercise we augment the word embedding with character embedding using a character-based Bi-LSTM. More parameters would be added to the model and the `Dataset` and the `nn.Module` classes should be modified accordingly. \n",
        "    \n",
        "More specifically, the following steps need to be completed in order to augment the model with character-based features:\n",
        "\n",
        "1. Similar to words, characters should be indexed (with a specification for the maximum number of characters considered in a word) \n",
        "\n",
        "2. The Dataset class should be modified to return a character-encoded representation along with a word-based one \n",
        "\n",
        "3. The architecture of the baseline model should also be changed. Two separate Embedding layers are needed to embed the two representations. Two LSTM layers are also  required (word-based and character-based). This means new Embedding and LSTM layers should be defined in the `__init__` section of the class which would only receive the character-based representations in each batch. The outputs of the char-based LSTM and word-based Embedding are then concatenated to form the combined representation which would be finally fed to the main LSTM of the model. \n",
        " \n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT7e_EZq44T1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0XRsLtWKAHh",
        "colab_type": "text"
      },
      "source": [
        "# * TO DO #5: Notes on Multi-task Learning\n",
        "\n",
        "<font size=\"4\"> \n",
        "  \n",
        "  Multi-task learning is an approach for jointly training multiple models. It can be simply implemented in neural networks by learning tasks in parallel while using a shared representation.\n",
        "  \n",
        "The simplest way is when we have different outputs for the same input and simultaneously train a model to predict the two or more outputs. \n",
        "  \n",
        "Parallel models can have both shared and independent layers.\n",
        "  \n",
        "  <figure>\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1LdwHoHlwm2wQj6SHUazYkNcavTCJp1_X\" width=\"400\" height=\"300\"/>\n",
        "<figcaption>Multi-task learning</figcaption></center>\n",
        "</figure>\n",
        "  \n",
        "In this excercise, we use the tags for chunking (which is provided in CONLL 2003 dataset in the third column) as our auxiliary outputs. The idea is that these two tasks can benefit from each other.\n",
        "  \n",
        "  \n",
        "The sections of the code that should be modified for multi-tasking are as follows:\n",
        "  \n",
        "\n",
        "\n",
        "* Modify `readfile()`, to read the chunking column as well\n",
        "* Create a dictionary that encode auxiliary tags\n",
        "* Return auxiliary tags from class `CoNLL2003NER(Dataset)`\n",
        "* Modify the model class. The architecture of the model will consist of one LSTM layer on top of embedding, then, two parallel LSTM layers, one to learn auxiliary tags and one to learn the main tags, and finally two Linear layers in similar fashion. The model returns two outputs accordingly.\n",
        "* In the training loop, two losses will be computed, one for main tags predictions and one for auxiliary tags prediction. Backpropagation would be performed based on the addition of the two losses.\n",
        " \n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-EBNpHxPHjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}