{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "synset_embeddings_wsd.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMPb9HkZkk9w",
        "colab_type": "text"
      },
      "source": [
        "#Sense Embeddings for Word Sense Disambiguation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTFbbEv97_er",
        "colab_type": "code",
        "outputId": "756f7e10-62fa-47f5-bd7d-6347944fb565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "# Install necessary libraries at the outset\n",
        "!pip install -q gensim\n",
        "!pip install -q conllu\n",
        "!pip install torch==1.2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/57/d5cceb0799c06733eefce80c395459f28970ebb9e896846ce96ab579a3f1/torch-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n",
            "\u001b[K     |████████████████████████████████| 748.9MB 16kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.2) (1.16.4)\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.1.0\n",
            "    Uninstalling torch-1.1.0:\n",
            "      Successfully uninstalled torch-1.1.0\n",
            "Successfully installed torch-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X8vVHHZkhS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "import copy\n",
        "import gensim\n",
        "import numpy\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "from conllu import parse\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from torch.utils.data import Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ucW643F1X8E",
        "colab_type": "code",
        "outputId": "0df28d85-f3ec-4c88-a0e8-a3c6e45d9e4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv4rwz665hM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings_path = \"/content/drive/My Drive/Session-2A/Embeddings/WordNet-Wikipedia-embeddings.txt\"\n",
        "train_data_path = \"/content/drive/My Drive/Session-2A/Data/semcor.tsv\" \n",
        "test_data_path = \"/content/drive/My Drive/Session-2A/Data/senseval2.tsv\" \n",
        "lexicon_path = \"/content/drive/My Drive/Session-2A/Data/wn30.txt\" \n",
        "f_sensekey2synset = \"/content/drive/My Drive/Session-2A/Data/sensekey2synset.pkl\" \n",
        "\n",
        "\n",
        "# Simple mapping between POS tags\n",
        "POS_MAP = {\"NOUN\": \"n\", \"VERB\": \"v\", \"ADJ\": \"a\", \"ADV\": \"r\"}\n",
        "CUSTOM_FIELDS = ('form', 'lemma', 'pos', 'synsets')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9s3hgKMjxrv",
        "colab_type": "text"
      },
      "source": [
        "## Load the embeddings\n",
        "We want to load the pretrained embeddings for synsets and lemmas. This includes getting the vectors, as well as dictionaries mapping integer indices to the string representation of words, and \n",
        "vice versa. We will use the gensim library to load the pretrained model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHTXG4mr4ony",
        "colab_type": "code",
        "outputId": "7e835cc8-d1ac-442b-d08e-2467000fd28e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "def load_embeddings(embeddings_path):\n",
        "  # Load with gensim\n",
        "  # Input file can be in binary ot text format\n",
        "  model = gensim.models.KeyedVectors.load_word2vec_format(embeddings_path, \n",
        "                                                          binary=False, \n",
        "                                                          datatype=numpy.float32)\n",
        "  embeddings = model.vectors\n",
        "  zeros = numpy.zeros(len(embeddings[0]), dtype=numpy.float32)\n",
        "  # Gensim provides a dict mapping ints to words (strings)\n",
        "  id2src = model.index2word\n",
        "  # We want to be able to go from words to ints as well\n",
        "  src2id = {v:(k+1) for k, v in enumerate(id2src)}\n",
        "  # Insert a zero vector for the padding symbol\n",
        "  src2id[\"<PAD>\"] = 0\n",
        "  embeddings = numpy.insert(embeddings, 0, copy.copy(zeros), axis=0)\n",
        "  # Make sure we have a vector for unknown inputs\n",
        "  if \"UNK\" not in src2id:\n",
        "      if \"unk\" in src2id:\n",
        "          src2id[\"<UNK>\"] = src2id[\"unk\"]\n",
        "          id2src[src2id[\"<UNK>\"]] = \"<UNK>\"\n",
        "          del src2id[\"unk\"]\n",
        "      else:\n",
        "          unk = numpy.zeros(len(embeddings[0]), dtype=numpy.float32)\n",
        "          src2id[\"<UNK>\"] = len(src2id)\n",
        "          embeddings = numpy.concatenate((embeddings, [unk]))\n",
        "  return embeddings, src2id, id2src\n",
        "  \n",
        "embeddings, src2id, id2src = load_embeddings(embeddings_path)\n",
        "embeddings = torch.Tensor(embeddings)\n",
        "embeddings_dim = embeddings.shape[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVVr3TewkIu5",
        "colab_type": "text"
      },
      "source": [
        "## Constructing a dictionary of the lexicon\n",
        "In order to do WSD with a predefined set of word senses, we first need to\n",
        "acquire such suitable representation of the lexicon. We get ours from \n",
        "the WordNet (WN) resource (http://wordnetweb.princeton.edu/perl/webwn). We will\n",
        "read a WN dictionary file and extract a mapping between the lemmas in the \n",
        "dictionary and all possible word senses (synsets) per lemma. Note that the\n",
        "function below allows us to include POS information per lemmas, i.e. to\n",
        "differentiate between instances of the same string when those are used as \n",
        "different POS categories. E.g. \"sleep\" as verb will match only verbal synsets\n",
        "in the dictionary, and \"sleep\" as a noun will match nominal synsets.\n",
        "\n",
        "*Sleep-n:*\n",
        "\n",
        "* sleep, slumber (a natural and periodic state of rest during which consciousness of the world is suspended) \"he didn't get enough sleep last night\"; \"calm as a child in dreamless slumber\"\n",
        "* sleep, sopor (a torpid state resembling deep sleep)\n",
        "* sleep, nap (a period of time spent sleeping) \"he felt better after a little sleep\"; \"there wasn't time for a nap\"\n",
        "* rest, eternal rest, sleep, eternal sleep, quietus (euphemisms for death (based on an analogy between lying in a bed and in a tomb)) \"she was laid to rest beside her husband\"; \"they had to put their family pet to sleep\"\n",
        "\n",
        "*Sleep-v:*\n",
        "\n",
        "* sleep, kip, slumber, log Z's, catch some Z's (be asleep)\n",
        "* sleep (be able to accommodate for sleeping) \"This tent sleeps six people\"\n",
        "\n",
        "\n",
        "Whether we want to use this option depends on whether we have available POS information \n",
        "from a previous processing step. In our case we do (encoded in the data sets),\n",
        "so we will use it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ycsFFTXFTtq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_wordnet_lexicon(lexicon_path, pos_filter=False):\n",
        "  lemma2synsets = {}\n",
        "  with open(lexicon_path, \"r\") as lexicon:\n",
        "    # Example line from the dictionary file:\n",
        "    # language 06282651-n:48 07109196-n:5 07051975-n:2 05808557-n:1 05650820-n:1 06304059-n:0  \n",
        "    for line in lexicon.readlines():\n",
        "      fields = line.split(\" \")\n",
        "      lemma_base, synsets = fields[0], fields[1:]\n",
        "      for i, entry in enumerate(synsets):\n",
        "        synset = entry[:10].strip()\n",
        "        if pos_filter:\n",
        "          pos = synset[-1]\n",
        "          lemma = lemma_base + \"-\" + pos\n",
        "        else:\n",
        "          lemma = lemma_base\n",
        "        if lemma not in lemma2synsets:\n",
        "          lemma2synsets[lemma] = [synset]\n",
        "        else:\n",
        "          lemma2synsets[lemma].append(synset)\n",
        "  lemma2synsets = collections.OrderedDict(sorted(lemma2synsets.items()))\n",
        "  return lemma2synsets\n",
        "  \n",
        "lemma2synsets = get_wordnet_lexicon(lexicon_path, pos_filter=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5LjplX5lqcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### TO DO 1 ###\n",
        "### Find the synsets IDs matching the lemma \"bear\" ###\n",
        "### Get a dictionary that discriminates between \"bear\" as verb, and as noun ###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9xpmxREk-rr",
        "colab_type": "text"
      },
      "source": [
        "## Dataset formats\n",
        "WSD data comes in various formats. One of the most popular formats lately has been that provided by the Universal Evaluation Framework (UEF): http://lcl.uniroma1.it/wsdeval/. The training and test datasets are available in UEF format in the Drive folder, in case you want to play with them, but today we are going to use a simpler format with tab-separated columns holding the following features per word:\n",
        "\n",
        "* wordform    \n",
        "* lemma    \n",
        "* POS    \n",
        "* synset-ID\n",
        "\n",
        "The .tsv files are already in the folder, but the transformation function is included here. You can examine and use it to transform the rest of the UEF files, if you want to play with them later on (you can download those from the UEF website). Note that you will need to provide the filepath to the sensekey2synset dictionary -- this is just a mapping between different IDs in WordNet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEexzV8Q0Ri2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform_uef2tsv(path_to_data, path_to_keys, output_path):\n",
        "  sensekey2synset = pickle.load(open(f_sensekey2synset, \"rb\"))\n",
        "  data, keys = \"\", \"\"\n",
        "  codes2keys = {}\n",
        "  f_codes2keys = open(path_to_keys, \"r\")\n",
        "  for line in f_codes2keys.readlines():\n",
        "    fields = line.strip().split()\n",
        "    codes2keys[fields[0]] = fields[1:]\n",
        "  corpora = ET.parse(path_to_data).getroot().findall(\"corpus\")\n",
        "  for corpus in corpora:\n",
        "    texts = corpus.findall(\"text\")\n",
        "    sentence_str = []\n",
        "    for text in texts:\n",
        "      sentences = text.findall(\"sentence\")\n",
        "      for sentence in sentences:\n",
        "        this_sent = \"\"\n",
        "        elements = sentence.findall(\".//\")\n",
        "        for element in elements:\n",
        "          wordform = element.text\n",
        "          lemma = element.get(\"lemma\")\n",
        "          pos = element.get(\"pos\")\n",
        "          if element.tag == \"instance\":\n",
        "            synsets = [sensekey2synset[key] for key in codes2keys[element.get(\"id\")]]\n",
        "          else:\n",
        "            synsets = [\"_\"]\n",
        "          this_sent += \"\\t\".join([wordform, lemma, pos, \",\".join(synsets)]) + \"\\n\"\n",
        "        sentence_str.append(this_sent)\n",
        "  dataset_str = \"\\n\".join(sentence_str)\n",
        "  with open(os.path.join(output_path, data.split(\".\")[0] + \".tsv\"), \"w\") as f:\n",
        "    f.write(dataset_str)\n",
        "  return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0PixFP2mNNG",
        "colab_type": "text"
      },
      "source": [
        "## Creating Dataset objects\n",
        "Now we need to read the data that we will be using for training and testing.\n",
        "PyTorch has the class Dataset which allows for data to be sampled on the fly,\n",
        "so that not all of the information needs to be kept in memory. We will extend \n",
        "the Dataset class to WSDataset, which simply parses the .tsv data, and then \n",
        "can supply samples from it which contain all the features needed by the \n",
        "neural network to train and classify senses. \n",
        "\n",
        "The helper function parse_tsv is used to read the .tsv file and the Sample\n",
        "class simply stores the different kinds of information per sample from the data \n",
        "set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeRyR5xqTItG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WSDataset(Dataset):\n",
        "\n",
        "  def __init__(self, tsv_file, src2id, embeddings, embeddings_dim, lemma2synsets):\n",
        "    # Our data has some pretty long sentences, so we will set a large max length\n",
        "    # Alternatively, can throw them out or truncate them\n",
        "    self.data = parse_tsv(open(tsv_file, \"r\").read(), max_length=300)\n",
        "    self.src2id = src2id\n",
        "    self.embeddings = embeddings\n",
        "    self.embeddings_dim = embeddings_dim\n",
        "    self.lemma2synsets = lemma2synsets\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    ''' Prepare one sample sentence of the data '''\n",
        "    # Get a sentence\n",
        "    sample = self.data[idx]\n",
        "    # Get an integer ID for each lemma in the sentence (<UNK> if unfamiliar)\n",
        "    # Note that we are working with lemmas for the input, not the word forms\n",
        "    inputs = [self.src2id[lemma] if lemma in self.src2id \n",
        "              else self.src2id[\"<UNK>\"] for lemma in sample.lemmas]\n",
        "    targets, neg_targets, mask = [], [], []\n",
        "    for i, label in enumerate(sample.synsets):\n",
        "      target, neg_target = torch.zeros(self.embeddings_dim), torch.zeros(self.embeddings_dim)\n",
        "      if label == \"_\":\n",
        "        mask.append(False)\n",
        "      else:\n",
        "        mask.append(True)\n",
        "        lemma_pos = sample.lemmas[i] + \"-\" + POS_MAP[sample.pos[i]] # e.g. \"bear-n\"\n",
        "        # Take care of cases of multiple labels, e.g. \"01104026-a,00357790-a\"\n",
        "        these_synsets = label.split(\",\")\n",
        "        for synset in these_synsets:\n",
        "          if synset in self.src2id:\n",
        "            synset_embedding = torch.Tensor(self.embeddings[self.src2id[synset]])\n",
        "            target += synset_embedding\n",
        "        target /= len(these_synsets)\n",
        "        # Pick negative targets too\n",
        "        # Copy the list of synsets, so that we don't change the dict\n",
        "        neg_options = copy.copy(self.lemma2synsets[lemma_pos])\n",
        "        for synset in these_synsets:\n",
        "          # Get rid of the gold synsets\n",
        "          neg_options.remove(synset)\n",
        "        while True:\n",
        "          # If no synsets remain in the list, pick any synset at random\n",
        "          if len(neg_options) == 0:\n",
        "            neg_synset = random.choice(list(self.src2id))\n",
        "            break\n",
        "          neg_synset = random.choice(neg_options)\n",
        "          # Make sure the chosen synset has a matching embedding, else remove from list\n",
        "          if neg_synset in self.src2id:\n",
        "            break\n",
        "          else:\n",
        "            neg_options.remove(neg_synset)\n",
        "        neg_target = torch.Tensor(self.embeddings[self.src2id[neg_synset]])\n",
        "      targets.append(target)\n",
        "      neg_targets.append(neg_target)\n",
        "    data = {\"lemmas\": sample.lemmas,\n",
        "            \"length\": sample.length,\n",
        "            \"pos\": sample.pos,\n",
        "            \"synsets\": sample.synsets,\n",
        "            \"inputs\": torch.tensor(inputs, dtype=torch.long),\n",
        "            \"targets\": torch.stack(targets).clone().detach(),\n",
        "            \"neg_targets\": torch.stack(neg_targets).clone().detach(),\n",
        "            \"mask\": torch.tensor(mask, dtype=torch.bool)}\n",
        "    return data\n",
        "\n",
        "class Sample():\n",
        "\n",
        "  def __init__(self):\n",
        "    ''' Simple structure to hold the sentence features '''\n",
        "    self.length = 0\n",
        "    self.forms = []\n",
        "    self.lemmas = []\n",
        "    self.pos = []\n",
        "    self.synsets = []\n",
        "\n",
        "def parse_tsv(f_dataset, max_length):\n",
        "  sentences = parse(f_dataset, CUSTOM_FIELDS)\n",
        "  data = []\n",
        "  for sentence in sentences:\n",
        "    sample = Sample()\n",
        "    for token in sentence:\n",
        "      sample.forms.append(token[\"form\"])\n",
        "      sample.lemmas.append(token[\"lemma\"])\n",
        "      sample.pos.append(token[\"pos\"])\n",
        "      sample.synsets.append(token[\"synsets\"])\n",
        "    sample.length = len(sample.forms)\n",
        "    # Take care to pad all sequences to the same length\n",
        "    sample.forms += (max_length - len(sample.forms)) * [\"<PAD>\"]\n",
        "    sample.lemmas += (max_length - len(sample.lemmas)) * [\"<PAD>\"]\n",
        "    sample.pos += (max_length - len(sample.pos)) * \"_\"\n",
        "    sample.synsets += (max_length - len(sample.synsets)) * \"_\"\n",
        "    data.append(sample)\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdS6XDKJM0zs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### TO DO 2 ###\n",
        "\n",
        "# Create datasets per the training and evaluation data \n",
        "trainset = WSDataset()\n",
        "testset = WSDataset()\n",
        "# Associate the datasets with dataloaders, specifying batch size and shuffling\n",
        "batch_size = 128\n",
        "trainloader = torch.utils.data.DataLoader()\n",
        "testloader = torch.utils.data.DataLoader()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "153xZABXmnHa",
        "colab_type": "text"
      },
      "source": [
        "## Defining the WSD architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxU354CTkPbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's now define the WSD model itself\n",
        "class WSDModel(nn.Module):\n",
        "\n",
        "  def __init__(self, embeddings_dim, embedding_weights, hidden_dim, \n",
        "               hidden_layers, dropout):\n",
        "      super(WSDModel, self).__init__()\n",
        "      self.hidden_layers = hidden_layers\n",
        "      self.hidden_dim = hidden_dim\n",
        "      # We can also initialize new embeddings here (see Sequence Tagging session)\n",
        "      self.word_embeddings = nn.Embedding.from_pretrained(embedding_weights, \n",
        "                                                          freeze=False)\n",
        "      self.lstm = nn.LSTM(embeddings_dim, \n",
        "                          hidden_dim, \n",
        "                          hidden_layers, \n",
        "                          bidirectional=True, \n",
        "                          batch_first=True, \n",
        "                          dropout=dropout)\n",
        "      ### TO DO 3 ###\n",
        "      # We want output with the size of the lemma&synset embeddings\n",
        "      self.output = \n",
        "\n",
        "  def forward(self, X, X_lengths, mask):\n",
        "      X = self.word_embeddings(X) # shape is [batch_size,max_length,embeddings_dim]\n",
        "      X = torch.nn.utils.rnn.pack_padded_sequence(X, \n",
        "                                                  X_lengths, \n",
        "                                                  batch_first=True, \n",
        "                                                  enforce_sorted=False)\n",
        "      X, _ = self.lstm(X)\n",
        "      # pad_packed_sequence cuts the sequences in the batch to the greatest sequence length\n",
        "      X, _ = torch.nn.utils.rnn.pad_packed_sequence(X, batch_first=True) # shape is [batch_size, max_length_of_X, 2* hidden_layer]\n",
        "      # Therefore, make sure mask has the same shape as X\n",
        "      mask = mask[:, :X.shape[1]] # shape is [batch_size, max_length_of_X]\n",
        "      # Make mask broadcastable to X\n",
        "      mask = torch.reshape(mask, (mask.shape[0], mask.shape[1], 1))\n",
        "      # Select only RNN outputs that correspond to synset-tagged words in the data\n",
        "      X = torch.masked_select(X, mask)\n",
        "      # masked_select flattens the tensor, but we need it as matrix \n",
        "      X = X.view(-1, 2 * self.hidden_dim) # shape is [num_labels, 2*hidden_dim]\n",
        "      outputs = self.output(X)\n",
        "      return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58oIi411mtWG",
        "colab_type": "text"
      },
      "source": [
        "## Specifying the model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odPfIOcGM6b7",
        "colab_type": "code",
        "outputId": "6e307279-b829-4ac3-e624-42a224ea0659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "n_hidden = 1000  \n",
        "hidden_layers = 1\n",
        "dropout = 0.2\n",
        "learning_rate = 0.2  \n",
        "alpha = 0.85 \n",
        "epochs = 100 \n",
        "### TO DO 4 ###\n",
        "model =  \n",
        "loss_function = torch.nn.MSELoss()\n",
        "# optimizer = torch.optim.Adam(model.parameters())\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9_2WY3XQ9mD",
        "colab_type": "text"
      },
      "source": [
        "## Define a method for choosing synset based on the RNN outputs and calculating accuracy\n",
        "The RNN model that we have only returns vectors at the ouput step, it doesn't tell us which synset we should choose in context. But we have taken care to calculate output vectors that are the same size as our lemma and synset embeddings in the pretrained vector space model. Therefore we use a distance metric, such as cosine similarity to compare the output vector to the vectors for the synsets we want to choose from. To get those, we need to consult the lexicon dictionary. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM_E9iJjQ8Tx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_accuracy(outputs, lemmas, pos, gold_synsets, lemma2synsets, embeddings, src2id, pos_filter=True):\n",
        "  matches, total = 0, 0\n",
        "  for i, output in enumerate(torch.unbind(outputs)):\n",
        "    if pos_filter:\n",
        "      lemma = lemmas[i] + \"-\" + POS_MAP[pos[i]]\n",
        "    else:\n",
        "      lemma = lemmas[i]\n",
        "    possible_synsets = lemma2synsets[lemma]\n",
        "    synset_choice, max_similarity = \"\", -100.0\n",
        "    for synset in possible_synsets:\n",
        "      synset_embedding = embeddings[src2id[synset]] if synset in src2id else embeddings[src2id[\"<UNK>\"]]\n",
        "      cos_sim = cosine_similarity(output.view(1, -1).detach().numpy(),\n",
        "                                  synset_embedding.view(1, -1).detach().numpy())[0][0]\n",
        "      if cos_sim > max_similarity:\n",
        "        max_similarity = cos_sim\n",
        "        synset_choice = synset\n",
        "    # Recall that sometime we have more than 1 gold synset, separated by commas\n",
        "    if synset_choice in gold_synsets[i].split(\",\"):\n",
        "      matches += 1\n",
        "    total += 1\n",
        "  return matches, total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i42a0VeCm0O8",
        "colab_type": "text"
      },
      "source": [
        "## Constructing the training and development loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MD3ZjhoglVoM",
        "colab_type": "code",
        "outputId": "0ff411a2-935c-4004-8537-47411f37e3a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# How often do we want to evaluate on the test data?\n",
        "eval_at = 10\n",
        "for epoch in range(epochs):\n",
        "  print(\"***** Start of epoch \" + str(epoch) + \" *****\")\n",
        "  # Keep track how the training loss changes across all steps\n",
        "  average_loss = 0.0\n",
        "  for step, data in enumerate(trainloader):\n",
        "    # Tell the model it is in training mode (so that e.g. dropout is applied)\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(data[\"inputs\"], data[\"length\"], data[\"mask\"])\n",
        "    # We want to use mask again in order to get only the targets and neg_targets for synsets\n",
        "    mask = torch.reshape(data[\"mask\"], (data[\"mask\"].shape[0], data[\"mask\"].shape[1], 1))\n",
        "    targets = torch.masked_select(data[\"targets\"], mask)\n",
        "    targets = targets.view(-1, 300) # shape is [num_labels, embedding_dim]\n",
        "    neg_targets = torch.masked_select(data[\"neg_targets\"], mask) \n",
        "    neg_targets = neg_targets.view(-1, 300) # ditto\n",
        "    # A straightforward loss function would be to just compute it on the outputs and gold label vectors:\n",
        "    # loss = loss_function(outputs, targets)\n",
        "    # But we can use the negative example as well to learn finer distinctions\n",
        "    ### TO DO 5 ###\n",
        "    loss = \n",
        "    loss.backward()\n",
        "    average_loss += loss\n",
        "    optimizer.step()\n",
        "    if step % eval_at == 0:\n",
        "      # Tell the model we are in eval mode\n",
        "      model.eval()\n",
        "      print(\"Step \" + str(step))\n",
        "      # In numpy we can use mask as an index into arrays\n",
        "      # But be careful to give them the same dimensions\n",
        "      lemmas = numpy.asarray(data['lemmas']).transpose()[data[\"mask\"]]\n",
        "      synsets = numpy.asarray(data['synsets']).transpose()[data[\"mask\"]]\n",
        "      pos = numpy.asarray(data['pos']).transpose()[data[\"mask\"]]\n",
        "      matches, total = calculate_accuracy(outputs, lemmas, pos, synsets, lemma2synsets,\n",
        "                                          embeddings, src2id, pos_filter=True)\n",
        "      train_accuracy = matches * 1.0 / total\n",
        "      print(\"Training accuracy at step \" + str(step) + \": \" + str(train_accuracy))\n",
        "      average_loss /= (eval_at if step != 0 else 1)\n",
        "      print(\"Average loss (training) is: \" + str(average_loss.detach().numpy()))\n",
        "      average_loss = 0.0\n",
        "      # Loop over the eval data\n",
        "      matches_all, total_all = 0, 0\n",
        "      for eval_data in testloader:\n",
        "        outputs = model(eval_data[\"inputs\"], eval_data[\"length\"], eval_data[\"mask\"])\n",
        "        lemmas = numpy.asarray(eval_data['lemmas']).transpose()[eval_data[\"mask\"]]\n",
        "        synsets = numpy.asarray(eval_data['synsets']).transpose()[eval_data[\"mask\"]]\n",
        "        pos = numpy.asarray(eval_data['pos']).transpose()[eval_data[\"mask\"]]\n",
        "        matches, total = calculate_accuracy(outputs, lemmas, pos, synsets, lemma2synsets,\n",
        "                                            embeddings, src2id, pos_filter=True)\n",
        "        matches_all += matches\n",
        "        total_all += total\n",
        "      test_accuracy = matches_all * 1.0 / total_all\n",
        "      print(\"Test accuracy at step \" + str(step) + \" is: \" + str(test_accuracy))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Start of epoch 0 *****\n",
            "Step 0\n",
            "Training accuracy at step 0: 0.35844471445929527\n",
            "Average loss (training) is: 0.1929859\n",
            "Test accuracy at step 0 is: 0.40709903593339175\n",
            "Step 10\n",
            "Training accuracy at step 10: 0.44740177439797213\n",
            "Average loss (training) is: 0.1919314\n",
            "Test accuracy at step 10 is: 0.45135845749342685\n",
            "Step 20\n",
            "Training accuracy at step 20: 0.48353096179183136\n",
            "Average loss (training) is: 0.19166212\n",
            "Test accuracy at step 20 is: 0.48115687992988604\n",
            "Step 30\n",
            "Training accuracy at step 30: 0.493844049247606\n",
            "Average loss (training) is: 0.19092858\n",
            "Test accuracy at step 30 is: 0.49780893952673094\n",
            "Step 40\n",
            "Training accuracy at step 40: 0.48435374149659866\n",
            "Average loss (training) is: 0.19016786\n",
            "Test accuracy at step 40 is: 0.5144609991235758\n",
            "Step 50\n",
            "Training accuracy at step 50: 0.5289672544080605\n",
            "Average loss (training) is: 0.18943569\n",
            "Test accuracy at step 50 is: 0.5311130587204207\n",
            "Step 60\n",
            "Training accuracy at step 60: 0.5655172413793104\n",
            "Average loss (training) is: 0.18892235\n",
            "Test accuracy at step 60 is: 0.5473269062226117\n",
            "Step 70\n",
            "Training accuracy at step 70: 0.5469293163383546\n",
            "Average loss (training) is: 0.18837218\n",
            "Test accuracy at step 70 is: 0.563102541630149\n",
            "Step 80\n",
            "Training accuracy at step 80: 0.5776223776223777\n",
            "Average loss (training) is: 0.18774763\n",
            "Test accuracy at step 80 is: 0.5832602979842244\n",
            "Step 90\n",
            "Training accuracy at step 90: 0.5843989769820972\n",
            "Average loss (training) is: 0.1870162\n",
            "Test accuracy at step 90 is: 0.5937773882559159\n",
            "Step 100\n",
            "Training accuracy at step 100: 0.6021361815754339\n",
            "Average loss (training) is: 0.18658745\n",
            "Test accuracy at step 100 is: 0.5985977212971078\n",
            "Step 110\n",
            "Training accuracy at step 110: 0.5611601513240857\n",
            "Average loss (training) is: 0.18595015\n",
            "Test accuracy at step 110 is: 0.6029798422436459\n",
            "Step 120\n",
            "Training accuracy at step 120: 0.6024844720496895\n",
            "Average loss (training) is: 0.18515047\n",
            "Test accuracy at step 120 is: 0.6060473269062226\n",
            "Step 130\n",
            "Training accuracy at step 130: 0.6290097629009763\n",
            "Average loss (training) is: 0.18504895\n",
            "Test accuracy at step 130 is: 0.6113058720420683\n",
            "Step 140\n",
            "Training accuracy at step 140: 0.6247113163972287\n",
            "Average loss (training) is: 0.18460196\n",
            "Test accuracy at step 140 is: 0.6143733567046451\n",
            "Step 150\n",
            "Training accuracy at step 150: 0.617693522906793\n",
            "Average loss (training) is: 0.183745\n",
            "Test accuracy at step 150 is: 0.6143733567046451\n",
            "Step 160\n",
            "Training accuracy at step 160: 0.5691906005221932\n",
            "Average loss (training) is: 0.18340448\n",
            "Test accuracy at step 160 is: 0.621384750219106\n",
            "Step 170\n",
            "Training accuracy at step 170: 0.5941422594142259\n",
            "Average loss (training) is: 0.18270926\n",
            "Test accuracy at step 170 is: 0.621384750219106\n",
            "Step 180\n",
            "Training accuracy at step 180: 0.6104651162790697\n",
            "Average loss (training) is: 0.18262626\n",
            "Test accuracy at step 180 is: 0.6231375985977213\n",
            "Step 190\n",
            "Training accuracy at step 190: 0.6127320954907162\n",
            "Average loss (training) is: 0.18210869\n",
            "Test accuracy at step 190 is: 0.6244522348816828\n",
            "Step 200\n",
            "Training accuracy at step 200: 0.5705045278137129\n",
            "Average loss (training) is: 0.18170568\n",
            "Test accuracy at step 200 is: 0.6235758106923751\n",
            "Step 210\n",
            "Training accuracy at step 210: 0.5952755905511811\n",
            "Average loss (training) is: 0.18130817\n",
            "Test accuracy at step 210 is: 0.6244522348816828\n",
            "Step 220\n",
            "Training accuracy at step 220: 0.5792349726775956\n",
            "Average loss (training) is: 0.18082821\n",
            "Test accuracy at step 220 is: 0.6240140227870289\n",
            "Step 230\n",
            "Training accuracy at step 230: 0.6173541963015647\n",
            "Average loss (training) is: 0.18077855\n",
            "Test accuracy at step 230 is: 0.6231375985977213\n",
            "Step 240\n",
            "Training accuracy at step 240: 0.5901442307692307\n",
            "Average loss (training) is: 0.18031359\n",
            "Test accuracy at step 240 is: 0.6222611744084137\n",
            "Step 250\n",
            "Training accuracy at step 250: 0.6084583901773534\n",
            "Average loss (training) is: 0.18010478\n",
            "Test accuracy at step 250 is: 0.6226993865030674\n",
            "Step 260\n",
            "Training accuracy at step 260: 0.6084724005134788\n",
            "Average loss (training) is: 0.17953716\n",
            "Test accuracy at step 260 is: 0.6226993865030674\n",
            "Step 270\n",
            "Training accuracy at step 270: 0.6104417670682731\n",
            "Average loss (training) is: 0.17939563\n",
            "Test accuracy at step 270 is: 0.6231375985977213\n",
            "Step 280\n",
            "Training accuracy at step 280: 0.6114285714285714\n",
            "Average loss (training) is: 0.17903611\n",
            "Test accuracy at step 280 is: 0.6231375985977213\n",
            "Step 290\n",
            "Training accuracy at step 290: 0.6017964071856288\n",
            "Average loss (training) is: 0.17882207\n",
            "Test accuracy at step 290 is: 0.6226993865030674\n",
            "***** Start of epoch 1 *****\n",
            "Step 0\n",
            "Training accuracy at step 0: 0.576056338028169\n",
            "Average loss (training) is: 0.1794368\n",
            "Test accuracy at step 0 is: 0.6235758106923751\n",
            "Step 10\n",
            "Training accuracy at step 10: 0.6041666666666666\n",
            "Average loss (training) is: 0.17849508\n",
            "Test accuracy at step 10 is: 0.6235758106923751\n",
            "Step 20\n",
            "Training accuracy at step 20: 0.6426940639269406\n",
            "Average loss (training) is: 0.1784746\n",
            "Test accuracy at step 20 is: 0.6222611744084137\n",
            "Step 30\n",
            "Training accuracy at step 30: 0.604551920341394\n",
            "Average loss (training) is: 0.17804404\n",
            "Test accuracy at step 30 is: 0.6226993865030674\n",
            "Step 40\n",
            "Training accuracy at step 40: 0.6159895150720839\n",
            "Average loss (training) is: 0.17779833\n",
            "Test accuracy at step 40 is: 0.6222611744084137\n",
            "Step 50\n",
            "Training accuracy at step 50: 0.6151162790697674\n",
            "Average loss (training) is: 0.17777182\n",
            "Test accuracy at step 50 is: 0.621384750219106\n",
            "Step 60\n",
            "Training accuracy at step 60: 0.6202860858257477\n",
            "Average loss (training) is: 0.17764027\n",
            "Test accuracy at step 60 is: 0.621384750219106\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-0bb58afb1d8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# But we can use the negative example as well to learn finer distinctions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# TO DO 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0maverage_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P693uc34Hj8F",
        "colab_type": "text"
      },
      "source": [
        "## Stuff to try out\n",
        "\n",
        "\n",
        "* Tuning the hyperparameters\n",
        "* Modifying the loss and changing the optimizer\n",
        "* Adding attention layers\n",
        "* Including additional tasks in a multi-task learning setup (e.g. WSD classifier, POS tagging, dependency parsing, semantic role labeler, etc.)\n",
        "* Dynamically swapping some of the inputs with gold synsets\n",
        "* Training on synthetic data (see http://ixa2.si.ehu.es/ukb/ for a software tool to generate artifical corpora)\n",
        "\n",
        "## References:\n",
        "\n",
        "\n",
        "* Camacho-Collados, José, Mohammad Taher Pilehvar, and Roberto Navigli. \"Nasari: a novel approach to a semantically-aware representation of items.\" Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2015.\n",
        "* Chen, Xinxiong, Zhiyuan Liu, and Maosong Sun. \"A unified model for word sense representation and disambiguation.\" Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2014.\n",
        "* Goikoetxea, Josu, Aitor Soroa, and Eneko Agirre. \"Random walks and neural network language models on knowledge bases.\" Proceedings of the 2015 conference of the North American Chapter of the Association for Computational Linguistics: Human language technologies. 2015.\n",
        "* Iacobacci, Ignacio, Mohammad Taher Pilehvar, and Roberto Navigli. \"Sensembed: Learning sense embeddings for word and relational similarity.\" Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 2015.\n",
        "* Johansson, Richard, and Luis Nieto Pina. \"Embedding a semantic network in a word space.\" Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2015.\n",
        "* Mancini, Massimiliano, et al. \"Embedding words and senses together via joint knowledge-enhanced training.\" arXiv preprint arXiv:1612.02703 (2016).\n",
        "* Rothe, Sascha, and Hinrich Schütze. \"Autoextend: Extending word embeddings to embeddings for synsets and lexemes.\" arXiv preprint arXiv:1507.01127 (2015).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0RpNQJPo1b7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}